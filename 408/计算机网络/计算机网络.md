# 计算机网络

## 其他内容

### 内网穿透原理：

内网的主机安装内网穿透的软件后，与内网穿透的服务器建立连接，服务器提供一个域名并且映射到内网的私有ip与端口，于是，通过访问内网穿透服务器就可以**实现从外到内的网络访问**，不需要公网ip，只需要把内部网络进行穿透，如图：

![https://image.itbaima.net/images/173/image-20231021216093930.png](https://image.itbaima.net/images/173/image-20231021216093930.png)

从内到外的访问：NAT地址转换协议(实现一个私有ip转换为一个公网ip，一对一地址转换)、NAPT协议(根据端口实现多对一的地址转换)

使用frp进行：

我们可以让家里的机器主动连接到云服务器，再由云服务器向我们家里的机器进行数据包转发，实现内网穿透的效果。

### 内网穿透实战,基于fps:

在内网的电脑上安装frp客户端，在服务器上安装frp服务端,以此实现内网穿透。

![https://image.itbaima.net/images/173/image-20231022203103460.png](https://image.itbaima.net/images/173/image-20231022203103460.png)



显而易见，内网穿透就是依靠转发的形式实现的，这样就可以让家里的设备实现外网访问了！

内网穿透优点：

- 省钱，计算资源、存储资源可以全部自行部署
- 安全，内网环境下只要限制好端口，黑客很难入侵
- 宽带大，家用宽带一般是10M上行速度起步（一般为下行速度的十分之一，百兆宽带一般指的是下行速度），办理千兆宽带甚至可以达到100M的上行速度，相比腾讯云的3M小宽带，直接真香，我们可以增加内网穿透服务器的数量并进行**负载均衡**来做到吃满上行带宽。

内网穿透缺点：

- 不稳定，停电、断网、电费等，都是我们需要考虑的因素
- 网络性能瓶颈，网络速度多快，以及能承受的QPS(Queries Per Second意思是“**每秒查询率**”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 )，全部受限于做内网穿透的云服务器上限。

#### 服务端部署frps服务

在GitHub上下载对应的frp程序，解压，然后上传frps到云服务器，执行：

```sh
chmod +x frps
./frps
```

这样就可以直接运行了：

接着我们来编写一下配置文件：

```sh
vim frps.toml
```

内容如下：

```properties
bindPort = 7000    #端口
auth.method = "token"   #验证方式
auth.token = "123456"   #token秘钥
```

以配置文件的方式运行，但是会卡在运行界面，想要后台运行，需要将其配置为Linux服务的形式：

~~~sh
./frps -c frps.toml
~~~



然后我们接着将其配置为Linux服务的形式运行：

文档：https://gofrp.org/zh-cn/

```sh
sudo vim /etc/systemd/system/frps.service
```

配置文件如下：

```properties
[Unit]
Description = frp server
After = network.target syslog.target
Wants = network.target

[Service]
Type = simple
ExecStart = /root/frps -c /root/frps.toml

[Install]
WantedBy = multi-user.target
```

然后我们就可以启动这个服务了：

```sh
systemctl enable frps
systemctl start frps
```

还有别忘了开防火墙端口，包括用于注册的7000端口以及后续给内网其他服务进行穿透的端口（如Nginx的80端口）

#### 在Ubuntu客户端上部署frpc服务

跟服务端一样，直接上传frpc客户端：

```sh
chmod +x frpc
./frpc
```

只不过需要先进行配置才能运行：

![image-20231019175038881](https://s2.loli.net/2023/10/19/MOAoDteFLchb2Hv.png)



接着我们来编写一下配置文件：

```sh
vim frpc.toml
```

内容如下：

```sh
serverAddr = "47.109.97.136"   //之前搭建好的内网穿透服务器地址
serverPort = 7000      //内网穿透服务器注册端口
auth.method = "token"  //使用token验证
auth.token = "123456"  //使用密码

[[proxies]]
name = "nginx"   //配置需要代理的本地服务名称，随便取
type = "tcp"     //类型选择tcp即可（大部分都是，因为http协议是基于tcp的）
localIP = "127.0.0.1"   //本地服务的IP地址，因为是直接部署在本地，所以说直接127.0.0.1，如果是部署中docker中，需要填写docker容器的ip地址
localPort = 80    //本地服务端口
remotePort = 80    //远程代理端口  外部访问remotePort端口时就会全部转发到localPort端口，响应也一样
```

配置完成后，就可以启动拉：

```sh
./frpc -c frpc.toml
```

![image-20231019180806628](https://s2.loli.net/2023/10/19/OhqUKHCSd5l4yBj.png)



为了方便，我们可以直接注册为服务：

```sh
sudo vim /etc/systemd/system/frpc.service
```

内容如下：

```sh
[Unit]
Description = frp client
After = network.target syslog.target
Wants = network.target

[Service]
Type = simple
ExecStart = /root/frpc -c /root/frpc.toml

[Install]
WantedBy = multi-user.target
```

然后我们就可以启动这个服务了：

```sh
systemctl enable frpc
systemctl start frpc
```

然后就可以试试看访问啦~

#### 开启管理面板

服务端开启管理面板，可以更加有效的监控流量情况：

![image-20231019181459596](https://s2.loli.net/2023/10/19/Zob8niGWe6Rfvum.png)



在服务端配置文件中添加以下内容：

```sh
webServer.port = 7500   #管理面板端口
webServer.addr = "0.0.0.0"   #绑定到所有网络上，即：允许所有的ip进行外网访问
webServer.user = "admin"  #管理员名称
webServer.password = "admin"  #管理员密码
```

然后就可以快乐的管理了~

## 趣谈网络协议的内容：

## 1.1 协议的三要素(语法、语义、顺序)

- **语法**，就是这一段内容要符合一定的规则和格式。例如，括号要成对，结束要使用分号等。
- **语义**，就是这一段内容要代表某种意义。例如数字减去数字是有意义的，数字减去文本一般来说就没有意义。
- **顺序**，就是先干啥，后干啥。例如，可以先加上某个数值，然后再减去某个数值。

当你想要买一个商品，常规的做法就是打开浏览器，输入购物网站的地址。浏览器就会给你显示一个缤纷多彩的页面。

那你有没有深入思考过，浏览器是如何做到这件事情的？它之所以能够显示缤纷多彩的页面，是因为它收到了一段来自HTTP协议的“东西”。我拿网易考拉来举例，格式就像下面这样：

```xml
HTTP/1.1 200 OK
Date: Tue, 27 Mar 2018 16:50:26 GMT
Content-Type: text/html;charset=UTF-8
Content-Language: zh-CN

<!DOCTYPE html>
<html>
<head>
<base href="https://pages.kaola.com/" />
<meta charset="utf-8"/> <title>网易考拉3周年主会场</title>
```

这符合协议的三要素吗？我带你来看一下。

首先，符合语法，也就是说，只有按照上面那个格式来，浏览器才认。例如，上来是**状态**，然后是**首部**，然后是**内容**。

第二，符合语义，就是要按照约定的意思来。例如，状态200，表述的意思是网页成功返回。如果不成功，就是我们常见的“404”。

第三，符合顺序，你一点浏览器，就是发送出一个HTTP请求，然后才有上面那一串HTTP返回的东西。

## 1.2 网络通信的过程

你先在浏览器里面输入 [https://www.kaola.com](https://www.kaola.com/) ，这是一个**URL**。浏览器只知道名字是“www.kaola.com”，但是不知道具体的地点，所以不知道应该如何访问。于是，它打开地址簿去查找。可以使用一般的地址簿协议**DNS**去查找，还可以使用另一种更加精准的地址簿查找协议**HTTPDNS**。

无论用哪一种方法查找，最终都会得到这个地址：106.114.138.24。这个是**IP**地址，是互联网世界的“门牌号”。

知道了目标地址，浏览器就开始打包它的请求。对于普通的浏览请求，往往会使用**HTTP**协议；但是对于购物的请求，往往需要进行加密传输，因而会使用**HTTPS**协议。无论是什么协议，里面都会写明“你要买什么和买多少”。﻿

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/d8a65ca347ad26acc9f1de49b10320c6.png)

DNS、HTTP、HTTPS所在的层我们称为**应用层**。经过应用层封装后，浏览器会将应用层的包交给下一层去完成，通过socket编程来实现。下一层是**传输层**。传输层有两种协议，一种是无连接的协议**UDP**，一种是面向连接的协议**TCP**。对于支付来讲，往往使用TCP协议。所谓的面向连接就是，TCP会保证这个包能够到达目的地。如果不能到达，就会重新发送，直至到达。

TCP协议里面会有两个端口，一个是浏览器监听的端口，一个是电商的服务器监听的端口。操作系统往往通过端口来判断，它得到的包应该给哪个进程。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/53c753a7d49c9dfe3cfeb26497e47eee.png)

传输层封装完毕后，浏览器会将包交给操作系统的**网络层**。网络层的协议是**IP协议**。在IP协议里面会有源IP地址，即浏览器所在机器的IP地址和目标IP地址，也即电商网站所在服务器的IP地址。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/459a421975b27f6187d2aa4673171f1b.png)

操作系统既然知道了目标IP地址，就开始想如何根据这个门牌号找到目标机器。操作系统往往会判断，这个目标IP地址是本地人，还是外地人。如果是本地人，从门牌号就能看出来，但是显然电商网站不在本地，而在遥远的地方。

操作系统知道要离开本地去远方。虽然不知道远方在何处，但是可以这样类比一下：如果去国外要去海关，去外地就要去**网关**。而操作系统启动的时候，就会被**DHCP协议**配置IP地址，以及默认的网关的IP地址192.168.1.1。

操作系统如何将IP地址发给网关呢？在本地通信基本靠吼，于是操作系统大吼一声，谁是192.168.1.1啊？网关会回答它，我就是，我的本地地址在村东头。这个本地地址就是**MAC**地址，而大吼的那一声是**ARP**协议。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/cc02190ac57af7fb6c3839534f2b674f.png)

于是操作系统将IP包交给了下一层，也就是**MAC层**。网卡再将包发出去。由于这个包里面是有MAC地址的，因而它能够到达网关。

网关收到包之后，会根据自己的知识，判断下一步应该怎么走。网关往往是一个路由器，到某个IP地址应该怎么走，这个叫作路由表。

路由器有点像玄奘西行路过的一个个国家的一个个城关。每个城关都连着两个国家，每个国家相当于一个局域网，在每个国家内部，都可以使用本地的地址MAC进行通信。

一旦跨越城关，就需要拿出IP头来，里面写着贫僧来自东土大唐（就是源IP地址），欲往西天拜佛求经（指的是目标IP地址）。路过宝地，借宿一晚，明日启行，请问接下来该怎么走啊？﻿

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/f7ea602aec91c67b35e710fb72a975e2.png)

城关往往是知道这些“知识”的，因为城关和临近的城关也会经常沟通。到哪里应该怎么走，这种沟通的协议称为**路由协议**，常用的有**OSPF**和**BGP**。﻿

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/b25ad7afba7b79331d95875dd0f451d4.png)

城关与城关之间是一个国家，当网络包知道了下一步去哪个城关，还是要使用国家内部的MAC地址，通过下一个城关的MAC地址，找到下一个城关，然后再问下一步的路怎么走，一直到走出最后一个城关。

最后一个城关知道这个网络包要去的地方。于是，对着这个国家吼一声，谁是目标IP啊？目标服务器就会回复一个MAC地址。网络包过关后，通过这个MAC地址就能找到目标服务器。

目标服务器发现MAC地址对上了，取下MAC头来，发送给操作系统的网络层。发现IP也对上了，就取下IP头。IP头里会写上一层封装的是TCP协议，然后将其交给传输层，即**TCP层**。

在这一层里，对于收到的每个包，都会有一个回复的包说明收到了。这个回复的包绝非这次下单请求的结果，例如购物是否成功，扣了多少钱等，而仅仅是TCP层的一个说明，即收到之后的回复。当然这个回复，会沿着刚才来的方向走回去，报个平安。

因为一旦出了国门，西行路上千难万险，如果在这个过程中，网络包走丢了，例如进了大沙漠，或者被强盗抢劫杀害怎么办呢？因而到了要报个平安。

如果过一段时间还是没到，发送端的TCP层会重新发送这个包，还是上面的过程，直到有一天收到平安到达的回复。**这个重试绝非你的浏览器重新将下单这个动作重新请求一次**。对于浏览器来讲，就发送了一次下单请求，TCP层不断自己闷头重试。除非TCP这一层出了问题，例如连接断了，才轮到浏览器的应用层重新发送下单请求。

当网络包平安到达TCP层之后，TCP头中有目标端口号，通过这个端口号，可以找到电商网站的进程正在监听这个端口号，假设一个Tomcat，将这个包发给电商网站。﻿

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/b465ccfafe333bfdfb9daf78f96e123f.png)

电商网站的进程得到HTTP请求的内容，知道了要买东西，买多少。往往一个电商网站最初接待请求的这个Tomcat只是个接待员，负责统筹处理这个请求，而不是所有的事情都自己做。例如，这个接待员要告诉专门管理订单的进程，登记要买某个商品，买多少，要告诉管理库存的进程，库存要减少多少，要告诉支付的进程，应该付多少钱，等等。

如何告诉相关的进程呢？往往通过**RPC调用**，即远程过程调用的方式来实现。远程过程调用就是当告诉管理订单进程的时候，接待员不用关心中间的网络互连问题，会由RPC框架统一处理。RPC框架有很多种，有基于HTTP协议放在HTTP的报文里面的，有直接封装在TCP报文里面的。

当接待员发现相应的部门都处理完毕，就回复一个HTTPS的包，告知下单成功。这个HTTPS的包，会像来的时候一样，经过千难万险到达你的个人电脑，最终进入浏览器，显示支付成功。

## 1.3 ip addr命令的结果解析：

怎么查看IP地址

Windows上是ipconfig，在Linux上是ifconfig。

那你知道在Linux上还有什么其他命令可以查看IP地址吗？答案是ip addr。

```sql
root@test:~# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff
    inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fec7:7975/64 scope link 
       valid_lft forever preferred_lft forever
```



### 1.3.1 ip地址的分类 A-E

本来32位的IP地址就不够，还被分成了5类。现在想想，当时分配地址的时候，真是太奢侈了。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/0b32d6e35ff0bbc5d46cfb87f6669d9e.jpg)

在网络地址中，至少在当时设计的时候，对于A、B、 C类主要分两部分，前面一部分是网络号，后面一部分是主机号。这很好理解，大家都是六单元1001号，我是小区A的六单元1001号，而你是小区B的六单元1001号。

下面这个表格，详细地展示了A、B、C三类地址所能包含的主机的数量。在后文中，我也会多次借助这个表格来讲解。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/e9c59a4b2f0b804356759b10440ea7be.jpg)

这里面有个尴尬的事情，就是C类地址能包含的最大主机数量实在太少了，只有254个。当时设计的时候恐怕没想到，现在估计一个网吧都不够用吧。而B类地址能包含的最大主机数量又太多了。6万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。

### 1.3.2 无类型域间选路（CIDR）10.100.122.2/24

于是有了一个折中的方式叫作**无类型域间选路**，简称**CIDR**。这种方式打破了原来设计的几类地址的做法，将32位的IP地址一分为二，前面是**网络号**，后面是**主机号**。从哪里分呢？你如果注意观察的话可以看到，10.100.122.2/24，这个IP地址中有一个斜杠，斜杠后面有个数字24。这种地址表示形式，就是CIDR。后面24的意思是，32位中，前24位是网络号，后8位是主机号。

伴随着CIDR存在的，一个是**广播地址**，10.100.122.255。如果发送这个地址，所有10.100.122网络里面的机器都可以收到。另一个是**子网掩码**，255.255.255.0。

将子网掩码和IP地址进行AND计算。前面三个255，转成二进制都是1。1和任何数值取AND，都是原来数值，因而前三个数不变，为10.100.122。后面一个0，转换成二进制是0，0和任何数值取AND，都是0，因而最后一个数变为0，合起来就是10.100.122.0。这就是**网络号**。**将子网掩码和IP地址按位计算AND，就可得到网络号。**



### 1.3.3 公有IP地址和私有IP地址

在日常的工作中，几乎不用划分A类、B类或者C类，所以时间长了，很多人就忘记了这个分类，而只记得CIDR。但是有一点还是要注意的，就是公有IP地址和私有IP地址。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/901778433f2d6e27b916e9e53c232d93.jpg)

我们继续看上面的表格。表格最右列是私有IP地址段。平时我们看到的数据中心里，办公室、家里或学校的IP地址，一般都是私有IP地址段。因为这些地址允许组织内部的IT人员自己管理、自己分配，而且可以重复。因此，你学校的某个私有IP地址段和我学校的可以是一样的。

这就像每个小区有自己的楼编号和门牌号，你们小区可以叫6栋，我们小区也叫6栋，没有任何问题。但是一旦出了小区，就需要使用公有IP地址。就像人民路888号，是国家统一分配的，不能两个小区都叫人民路888号。

公有IP地址有个组织统一分配，你需要去买。如果你搭建一个网站，给你学校的人使用，让你们学校的IT人员给你一个IP地址就行。但是假如你要做一个类似网易163这样的网站，就需要有公有IP地址，这样全世界的人才能访问。

**表格中的192.168.0.x是最常用的私有IP地址。你家里有Wi-Fi，对应就会有一个IP地址。一般你家里地上网设备不会超过256个，所以/24基本就够了。有时候我们也能见到/16的CIDR，这两种是最常见的，也是最容易理解的。**

不需要将十进制转换为二进制32位，就能明显看出192.168.0是网络号，后面是主机号。而整个网络里面的第一个地址192.168.0.1，往往就是你这个私有网络的出口地址。例如，你家里的电脑连接Wi-Fi，Wi-Fi路由器的地址就是192.168.0.1，而192.168.0.255就是广播地址。一旦发送这个地址，整个192.168.0网络里面的所有机器都能收到。

但是也不总都是这样的情况。因此，其他情况往往就会很难理解，还容易出错。

### 1.3.4 举例：一个容易“犯错”的CIDR

我们来看16.158.165.91/22这个CIDR。求一下这个网络的第一个地址、子网掩码和广播地址。

你要是上来就写16.158.165.1，那就大错特错了。

/22不是8的整数倍，不好办，只能先变成二进制来看。16.158的部分不会动，它占了前16位。中间的165，变为二进制为‭10100101‬。除了前面的16位，还剩6位。所以，这8位中前6位是网络号，16.158.<101001>，而<01>.91是机器号。

第一个地址是16.158.<101001><00>.1，即16.158.164.1。子网掩码是255.255.<111111><00>.0，即255.255.252.0。广播地址为16.158.<101001><11>.255，即16.158.167.255。

这五类地址中，还有一类D类是**组播地址**。使用这一类地址，属于某个组的机器都能收到。这有点类似在公司里面大家都加入了一个邮件组。发送邮件，加入这个组的都能收到。组播地址在后面讲述VXLAN协议的时候会提到。

讲了这么多，才讲了上面的输出结果中很小的一部分，是不是觉得原来并没有真的理解ip addr呢？我们接着来分析。

在IP地址的后面有个scope，对于eth0这张网卡来讲，是global，说明这张网卡是可以对外的，可以接收来自各个地方的包。对于lo来讲，是host，说明这张网卡仅仅可以供本机相互通信。

lo全称是**loopback**，又称**环回接口**，往往会被分配到127.0.0.1这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。

### 1.3.5 MAC地址

在IP地址的上一行是link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为**MAC地址**，是一个网卡的物理地址，用十六进制，6个byte表示。

**整个互联网的通信，全部用MAC地址可以吗？为什么？**

这样当然是不行的。 **一个网络包要从一个地方传到另一个地方，除了要有确定的地址，还需要有定位功能。** 而**有门牌号码属性的IP地址，才是有远程定位功能的。**

例如，你去杭州市网商路599号B楼6层找刘超，你在路上问路，可能被问的人不知道B楼是哪个，但是可以给你指网商路怎么去。但是如果你问一个人，你知道这个身份证号的人在哪里吗？可想而知，没有人知道。

**MAC地址更像是身份证，是一个唯一的标识。**它的唯一性设计是为了组网的时候，不同的网卡放在一个网络里面的时候，可以不用担心冲突。**从硬件角度，保证不同的网卡有不同的标识。**

MAC地址是有一定定位功能的，只不过范围非常有限。你可以根据IP地址，找到杭州市网商路599号B楼6层，但是依然找不到我，你就可以靠吼了，大声喊身份证XXXX的是哪位？我听到了，我就会站起来说，是我啊。但是如果你在上海，到处喊身份证XXXX的是哪位，我不在现场，当然不会回答，因为我在杭州不在上海。

所以，**MAC地址的通信范围比较小，局限在一个子网里面。**例如，从192.168.0.2/24访问192.168.0.3/24是可以用MAC地址的。一旦跨子网，即从192.168.0.2/24到192.168.1.2/24，MAC地址就不行了，需要IP地址起作用了。

一个物理地址，叫作**链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以它常被称为MAC地址**。

第二层的网络包**格式**。对于以太网，第二层的最开始，就是目标的MAC地址和源的MAC地址。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/cef93d665ca863fef40f7f854d5d33ed.jpg)

接下来是**类型**，大部分的类型是IP数据包，然后IP里面包含TCP、UDP，以及HTTP等，这都是里层封装的事情。

有了这个目标MAC地址，数据包在链路上广播，MAC的网卡才能发现，这个包是给它的。MAC的网卡把包收进来，然后打开IP包，发现IP地址也是自己的，再打开TCP包，发现端口是自己，也就是80，而nginx就是监听80。

于是将请求提交给nginx，nginx返回一个网页。然后将网页需要发回请求的机器。然后层层封装，最后到MAC层。因为来的时候有源MAC地址，返回的时候，源MAC就变成了目标MAC，再返给请求的机器。

**MAC头的细节：**

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/798467df661ecf5632d67b9c58bc53fc.jpg)

### 1.3.6 网络设备的状态标识

解析完了MAC地址，我们再来看 是干什么的？这个叫作**net_device flags**，**网络设备的状态标识**。

UP表示网卡处于启动的状态；BROADCAST表示这个网卡有广播地址，可以发送广播包；MULTICAST表示网卡可以发送多播包；LOWER_UP表示L1是启动的，也即网线插着呢。MTU1500是指什么意思呢？是哪一层的概念呢？最大传输单元MTU为1500，这是以太网的默认值。

上一节，我们讲过网络包是层层封装的。**MTU是二层MAC层的概念**。MAC层有MAC的头，以太网规定连MAC头带正文合起来，不允许超过1500个字节。正文里面有IP的头、TCP的头、HTTP的头。如果放不下，就需要分片来传输。

qdisc pfifo_fast是什么意思呢？qdisc全称是**queueing discipline**，中文叫**排队规则**。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的qdisc（排队规则）把数据包加入队列。

最简单的qdisc是pfifo，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。pfifo_fast稍微复杂一些，它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。

三个波段（band）的优先级也不相同。band 0的优先级最高，band 2的最低。如果band 0里面有数据包，系统就不会处理band 1里面的数据包，band 1和band 2之间也是一样。

数据包是按照服务类型（**Type of Service，TOS**）被分配到三个波段（band）里面的。TOS是IP头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的。

队列是个好东西，后面我们讲云计算中的网络的时候，会有很多用户共享一个网络出口的情况，这个时候如何排队，每个队列有多粗，队列处理速度应该怎么提升，我都会详细为你讲解。

### 1.3.7 小结

怎么样，看起来很简单的一个命令，里面学问很大吧？通过这一节，希望你能记住以下的知识点，后面都能用得上：

- IP是地址，有定位功能；MAC是身份证，无定位功能；
- CIDR可以用来判断是不是本地人；
- IP分公有的IP和私有的IP。后面的章节中我会谈到“出国门”，就与这个有关。

## 2 常见协议

### 2.1 ARP协议

一个广播的网络里面接入了N台机器，我怎么知道每个MAC地址是谁呢？这就是**ARP协议**，也就是已知IP地址，求MAC地址的协议。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/17ac2f46ef531e2b4380300f10267e3d.jpg)

在一个局域网里面，当知道了IP地址，不知道MAC怎么办呢？靠“吼”。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/5fe88a40a8b5d507601968efb50ac668.jpg)

广而告之，发送一个广播包，谁是这个IP谁来回答。具体询问和回答的报文就像下面这样：

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/2bc53afb25515e96d0e646e297b1ce2f.jpg)

为了避免每次都用ARP请求，机器本地也会进行ARP缓存。当然机器会不断地上线下线，IP也可能会变，所以ARP的MAC地址缓存过一段时间就会过期。

根据ip地址获取MAC地址,只有是同一个网段的，它才会发送ARP请求，获取MAC地址。例如：发送数据到同一个网段的网关，则会根据网关的ip地址获取MAC地址，然后写入到mac头中，从而能够发送定位到网关，成功发送数据。

为了避免每次都用ARP请求，机器本地也会进行ARP缓存。当然机器会不断地上线下线，IP也可能会变，所以ARP的MAC地址缓存过一段时间就会过期。

### 2.2 动态主机配置协议（DHCP）

原来配置IP有这么多门道儿啊。你可能会问了，配置了IP之后一般不能变的，配置一个服务端的机器还可以，但是如果是客户端的机器呢？我抱着一台笔记本电脑在公司里走来走去，或者白天来晚上走，每次使用都要配置IP地址，那可怎么办？还有人事、行政等非技术人员，如果公司所有的电脑都需要IT人员配置，肯定忙不过来啊。

因此，我们需要有一个自动配置的协议，也就是称**动态主机配置协议（Dynamic Host Configuration Protocol）**，简称**DHCP**。

有了这个协议，网络管理员就轻松多了。他只需要配置一段共享的IP地址。每一台新接入的机器都通过DHCP协议，来这个共享的IP地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。

所以说，**如果是数据中心里面的服务器，IP一旦配置好，基本不会变，这就相当于买房自己装修。DHCP的方式就相当于租房。你不用装修，都是帮你配置好的。你暂时用一下，用完退租就可以了。**

#### 2.2.1  解析DHCP的工作方式

当一台机器新加入一个网络的时候，肯定一脸懵，啥情况都不知道，只知道自己的MAC地址。怎么办？先吼一句，我来啦，有人吗？这时候的沟通基本靠“吼”。这一步，我们称为**DHCP Discover。**

新来的机器使用IP地址0.0.0.0发送了一个广播包，目的IP地址为255.255.255.255。广播包封装了UDP，UDP封装了BOOTP。其实DHCP是BOOTP的增强版，但是如果你去抓包的话，很可能看到的名称还是BOOTP协议。

在这个广播包里面，新人大声喊：我是新来的（Boot request），我的MAC地址是这个，我还没有IP，谁能给租给我个IP地址！

格式就像这样：

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/395b304f49559034af34c882bd86f11f.jpg)

如果一个网络管理员在网络里面配置了**DHCP Server**的话，他就相当于这些IP的管理员。他立刻能知道来了一个“新人”。这个时候，我们可以体会MAC地址唯一的重要性了。当一台机器带着自己的MAC地址加入一个网络的时候，MAC是它唯一的身份，如果连这个都重复了，就没办法配置了。

只有MAC唯一，IP管理员才能知道这是一个新人，需要租给它一个IP地址，这个过程我们称为**DHCP Offer**。同时，DHCP Server为此客户保留为它提供的IP地址，从而不会为其他DHCP客户分配此IP地址。

DHCP Offer的格式就像这样，里面有给新人分配的地址。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/54ffefbe4f493f0f4a39f45504bd5086.jpg)

DHCP Server仍然使用广播地址作为目的地址，因为，此时请求分配IP的新人还没有自己的IP。DHCP Server回复说，我分配了一个可用的IP给你，你看如何？除此之外，服务器还发送了子网掩码、网关和IP地址租用期等信息。

新来的机器很开心，它的“吼”得到了回复，并且有人愿意租给它一个IP地址了，这意味着它可以在网络上立足了。当然更令人开心的是，如果有多个DHCP Server，这台新机器会收到多个IP地址，简直受宠若惊。

它会选择其中一个DHCP Offer，一般是最先到达的那个，并且会向网络发送一个DHCP Request广播数据包，包中包含客户端的MAC地址、接受的租约中的IP地址、提供此租约的DHCP服务器地址等，并告诉所有DHCP Server它将接受哪一台服务器提供的IP地址，告诉其他DHCP服务器，谢谢你们的接纳，并请求撤销它们提供的IP地址，以便提供给下一个IP租用请求者。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/e1e45ba0d86d2774ec80a1d86f87b724.jpg)

此时，由于还没有得到DHCP Server的最后确认，客户端仍然使用0.0.0.0为源IP地址、255.255.255.255为目标地址进行广播。在BOOTP里面，接受某个DHCP Server的分配的IP。

当DHCP Server接收到客户机的DHCP request之后，会广播返回给客户机一个DHCP ACK消息包，表明已经接受客户机的选择，并将这一IP地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/7da571c18b974582a9cfe4718c5dea0e.jpg)

最终租约达成的时候，还是需要广播一下，让大家都知道。

#### 2.2.2 IP地址的收回和续租

既然是租房子，就是有租期的。租期到了，管理员就要将IP收回。

如果不用的话，收回就收回了。就像你租房子一样，如果还要续租的话，不能到了时间再续租，而是要提前一段时间给房东说。DHCP也是这样。

客户机会在租期过去50%的时候，直接向为其提供IP地址的DHCP Server发送DHCP request消息包。客户机接收到该服务器回应的DHCP ACK消息包，会根据包中所提供的新的租期以及其他已经更新的TCP/IP参数，更新自己的配置。这样，IP租用更新就完成了。

### 2.3 PXE协议

#### 2.3.1 预启动执行环境（PXE）

普通的笔记本电脑，一般不会有这种需求。因为你拿到电脑时，就已经有操作系统了，即便你自己重装操作系统，也不是很麻烦的事情。但是，在数据中心里就不一样了。数据中心里面的管理员可能一下子就拿到几百台空的机器，一个个安装操作系统，会累死的。

所以管理员希望的不仅仅是自动分配IP地址，还要自动安装系统。装好系统之后自动分配IP地址，直接启动就能用了，这样当然最好了！

这事儿其实仔细一想，还是挺有难度的。安装操作系统，应该有个光盘吧。数据中心里不能用光盘吧，想了一个办法就是，可以将光盘里面要安装的操作系统放在一个服务器上，让客户端去下载。但是客户端放在哪里呢？它怎么知道去哪个服务器上下载呢？客户端总得安装在一个操作系统上呀，可是这个客户端本来就是用来安装操作系统的呀？

其实，这个过程和操作系统启动的过程有点儿像。首先，启动BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的MBR启动扇区，将GRUB启动起来；然后将权力交给GRUB，GRUB加载内核、加载作为根文件系统的initramfs文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。

那我们安装操作系统的过程，只能插在BIOS启动之后了。因为没安装系统之前，连启动扇区都没有。因而这个过程叫做**预启动执行环境（Pre-boot Execution Environment）**，简称**PXE。**

**PXE协议**分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在BIOS里面。当计算机启动时，BIOS把PXE客户端调入内存里面，就可以连接到服务端做一些操作了。

首先，PXE客户端自己也需要有个IP地址。因为PXE的客户端启动起来，就可以发送一个DHCP的请求，让DHCP Server给它分配一个地址。PXE客户端有了自己的地址，那它怎么知道PXE服务器在哪里呢？对于其他的协议，都好办，要么人告诉他。例如，告诉浏览器要访问的IP地址，或者在配置中告诉它；例如，微服务之间的相互调用。

但是PXE客户端启动的时候，啥都没有。好在DHCP Server除了分配IP地址以外，还可以做一些其他的事情。这里有一个DHCP Server的一个样例配置：

```lua
ddns-update-style interim;
ignore client-updates;
allow booting;
allow bootp;
subnet 192.168.1.0 netmask 255.255.255.0
{
option routers 192.168.1.1;
option subnet-mask 255.255.255.0;
option time-offset -18000;
default-lease-time 21600;
max-lease-time 43200;
range dynamic-bootp 192.168.1.240 192.168.1.250;
filename "pxelinux.0";
next-server 192.168.1.180;
}
```

按照上面的原理，默认的DHCP Server是需要配置的，无非是我们配置IP的时候所需要的IP地址段、子网掩码、网关地址、租期等。如果想使用PXE，则需要配置next-server，指向PXE服务器的地址，另外要配置初始启动文件filename。

这样PXE客户端启动之后，发送DHCP请求之后，除了能得到一个IP地址，还可以知道PXE服务器在哪里，也可以知道如何从PXE服务器上下载某个文件，去初始化操作系统。

#### 2.3.2  解析PXE的工作过程

接下来我们来详细看一下PXE的工作过程。

首先，启动PXE客户端。第一步是通过DHCP协议告诉DHCP Server，我刚来，一穷二白，啥都没有。DHCP Server便租给它一个IP地址，同时也给它PXE服务器的地址、启动文件pxelinux.0。

其次，PXE客户端知道要去PXE服务器下载这个文件后，就可以初始化机器。于是便开始下载，下载的时候使用的是**TFTP协议**。所以PXE服务器上，往往还需要有一个TFTP服务器。PXE客户端向TFTP服务器请求下载这个文件，TFTP服务器说好啊，于是就将这个文件传给它。

然后，PXE客户端收到这个文件后，就开始执行这个文件。这个文件会指示PXE客户端，向TFTP服务器请求计算机的配置信息pxelinux.cfg。TFTP服务器会给PXE客户端一个配置文件，里面会说内核在哪里、initramfs在哪里。PXE客户端会请求这些文件。

最后，启动Linux内核。一旦启动了操作系统，以后就啥都好办了。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/6e69007db3fc68ff6da8496266abf6a4.jpg)

#### 2.3.3 小结

好了，这一节就到这里了。我来总结一下今天的内容：

- DHCP协议主要是用来给客户租用IP地址，和房产中介很像，要商谈、签约、续租，广播还不能“抢单”；
- DHCP协议能给客户推荐“装修队”PXE，能够安装操作系统，这个在云计算领域大有用处。

最后，学完了这一节，给你留两个思考题吧。

1. PXE协议可以用来安装操作系统，但是如果每次重启都安装操作系统，就会很麻烦。你知道如何使得第一次安装操作系统，后面就正常启动吗？
2. 现在上网很简单了，买个家用路由器，连上WIFI，给DHCP分配一个IP地址，就可以上网了。那你是否用过更原始的方法自己组过简单的网呢？说来听听。





##  3 交换机、STP协议、VLAN

### 如何在宿舍里自己组网玩联机游戏？

#### 1 一根网线 连接两台电脑

你的网线是要电脑连电脑啊，还是电脑连网口啊？

我们要的是电脑连电脑。这种方式就是一根网线，有两个头。一头插在一台电脑的网卡上，另一头插在另一台电脑的网卡上。但是在当时，普通的网线这样是通不了的，所以水晶头要做交叉线，用的就是所谓的**1－3**、**2－6交叉接法**。就能够在物理层实现一端发送的信号，另一端能收到。

当然电脑连电脑，除了**网线要交叉**，还需要**配置这两台电脑的IP地址、子网掩码和默认网关**。要想两台电脑能够通信，这三项必须配置成为一个网络，可以一个是192.168.0.1/24，另一个是192.168.0.2/24，否则是不通的。

#### 2 集线器 连接三台电脑

有一个叫作**Hub**的东西，也就是**集线器**。这种设备有多个口，可以将宿舍里的多台电脑连接起来。但是，和交换机不同，集线器没有大脑，**它完全在物理层工作**。它会将自己收到的每一个字节，都复制到其他端口上去（广播的模式）。这是第一层物理层联通的方案。

出现的问题：

1. 这个包是发给谁的？谁应该接收？(Mac地址，ARP协议)
2. 大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？(信道划分、轮流协议、随机接入协议)
3. 如果发送的时候出现了错误，怎么办？(**CRC**，也就是**循环冗余检测**)

#### 3 交换机（连接上百台机器）

因为每个口都只连接一台电脑，这台电脑又不怎么换IP和MAC地址，只要记住这台电脑的MAC地址，如果目标MAC地址不是这台电脑的，这个口就不用转发了。

谁能知道目标MAC地址是否就是连接某个口的电脑的MAC地址呢？这就需要一个能把MAC头拿下来，检查一下目标MAC地址，然后根据策略转发的设备，按第二节课中讲过的，这个设备显然是个**二层设备**，我们称为**交换机**。

交换机怎么知道每个口的电脑的MAC地址呢？这需要**交换机会学习**。

一台MAC1电脑将一个包发送给另一台MAC2电脑，当这个包到达交换机的时候，一开始交换机也不知道MAC2的电脑在哪个口，所以没办法，它只能将包转发给除了来的那个口之外的其他所有的口。但是，这个时候，交换机会干一件非常聪明的事情，就是交换机会记住，MAC1是来自一个明确的口。以后有包的目的地址是MAC1的，直接发送到这个口就可以了。

当交换机作为一个关卡一样，过了一段时间之后，就有了整个网络的一个结构了，这个时候，基本上不用广播了，全部可以准确转发。当然，每个机器的IP地址会变，所在的口也会变，因而交换机上的学习的结果，我们称为**转发表**，是有一个过期时间的。

**工作原理：**

**两台交换机**的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器1只知道机器4的IP地址，当它想要访问机器4，把包发出去的时候，它必须要知道机器4的MAC地址。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/7a40046c5a2c7f7cd3c95b54488b9773.jpg)

于是机器1发起ARP广播，机器2收到这个广播，但是这不是找它的，所以没它什么事。交换机A一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，除了广播包来的方向外，它还要转发给其他所有的网口。于是机器3也收到广播信息了，但是这和它也没什么关系。

当然，交换机B也是能够收到广播信息的，但是这时候它也是不知道任何拓扑信息的，因而也是进行广播的策略，将包转发到局域网三。这个时候，机器4和机器5都收到了广播信息。机器4主动响应说，这是找我的，这是我的MAC地址。于是一个ARP请求就成功完成了。

在上面的过程中，交换机A和交换机B都是能够学习到这样的信息：机器1是在左边这个网口的。当了解到这些拓扑信息之后，情况就好转起来。当机器2要访问机器1的时候，机器2并不知道机器1的MAC地址，所以机器2会发起一个ARP请求。这个广播消息会到达机器1，也同时会到达交换机A。这个时候交换机A已经知道机器1是不可能在右边的网口的，所以这个广播信息就不会广播到局域网二和局域网三。

当机器3要访问机器1的时候，也需要发起一个广播的ARP请求。这个时候交换机A和交换机B都能够收到这个广播请求。交换机A当然知道主机A是在左边这个网口的，所以会把广播消息转发到局域网一。同时，交换机B收到这个广播消息之后，由于它知道机器1是不在右边这个网口的，所以不会将消息广播到局域网三。

#### 4 使用路由器进行联网

还记得咱们在宿舍的时候买了台交换机，几台机器组了一个局域网打游戏吗？可惜啊，只能打局域网的游戏，不能上网啊！盼啊盼啊，终于盼到大二，允许宿舍开通网络了。学校给每个宿舍的网口分配了一个IP地址。这个IP是校园网的IP，完全由网管部门控制。宿舍网的IP地址多为192.168.1.x。校园网的IP地址，假设是10.10.x.x。

这个时候，你要在宿舍上网，有两个办法：

第一个办法，让你们宿舍长再买一个网卡。这个时候，你们宿舍长的电脑里就有两张网卡。一张网卡的线插到你们宿舍的交换机上，另一张网卡的线插到校园网的网口。而且，这张新的网卡的IP地址要按照学校网管部门分配的配置，不然上不了网。**这种情况下，如果你们宿舍的人要上网，就需要一直开着宿舍长的电脑。**

第二个办法，你们共同出钱买个家庭路由器（反正当时我们买不起）。家庭路由器会有内网网口和外网网口。把外网网口的线插到校园网的网口上，将这个外网网口配置成和网管部的一样。内网网口连上你们宿舍的所有的电脑。**这种情况下，如果你们宿舍的人要上网，就需要一直开着路由器。**

这两种方法其实是一样的。只不过第一种方式，让你的宿舍长的电脑，变成一个有多个口的路由器而已。而你买的家庭路由器，里面也跑着程序，和你宿舍长电脑里的功能一样，只不过是一个嵌入式的系统。

当你的宿舍长能够上网之后，接下来，就是其他人的电脑怎么上网的问题。这就需要配置你们的**网卡。当然DHCP是可以默认配置的。在进行网卡配置的时候，除了IP地址，还需要配置一个Gateway**的东西，这个就是**网关**。



### 如何解决广播问题和安全问题？
1.物理隔离:
每个部门设一个单独的会议室，对应到网络方面，就是每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了。这样的问题在于，有的部门人多，有的部门人少。人少的部门慢慢人会变多，人多的部门也可能人越变越少。如果每个部门有单独的交换机，口多了浪费，少了又不够用。

2.虚拟隔离:就是用我们常说的VLAN，或者叫虚拟局域网。使用VLAN，一个交换机上会连属于多个局域网的机器，那交换机怎么区分哪个机器属于哪个局域网呢？

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/2ede82f511ccac2570c17a62ffc749ed.jpg)

只需要**在原来的二层的头上加一个TAG，里面有一个VLAN ID**，一共12位，可划分4096个VLAN ID。如果我们买的交换机是支持VLAN的，当这个交换机把二层的头取下来的时候，就能够识别这个VLAN ID。这样只有相同VLAN的包，才会互相转发，不同VLAN的包，是看不到的。这样广播问题和安全问题就都能够解决了。

​		**大致流程**：机器1连接交换机A的一个口，这个口为VLAN1,机器8同理，也连接了一个VLAN1的口，当机器1发送的VLAN ID为1的包到达交换机A时，交换机A取下包中的TAG，查看里面的VLAN ID，发现是VLAN1,于是转发到其他VLAN1的口和Trunk口，机器B于是能够从VLAN 1的口中收到包，交换机B也收到从Trunk传输的VLAN ID为1的包，也转发给自己的口中的VLAN1，于是机器3也能够收到包，最终达成了VLAN 1的包只转发给了VLAN 1的口。

​       而且对于交换机来讲，每个VLAN的口都是可以重新设置的。**将两个交换机连接起来的口应该设置成什么VLAN呢？**对于支持VLAN的交换机，有一种口叫作**Trunk口**。它可以转发属于任何VLAN的口。交换机之间可以通过这种口相互连接。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/a134027334616274cf27f18841f7504c.jpg)

### 小结：

1.当交换机的数目越来越多的时候，会遭遇环路问题，让网络包迷路，这就需要使用**STP协议**(复杂)，通过华山论剑比武的方式，将有环路的图变成没有环路的树，从而解决环路问题。
2.交换机数目多会面临广播问题和安全问题,可以通过**VLAN**形成虚拟局域网，从而解决广播问题和安全问题。

## 4 ping命令解析:

ping是基于ICMP协议工作的。ICMP报文是封装在IP包里面的。因为传输指令的时候，肯定需要源地址和目标地址。ICMP报文有很多的类型，不同的类型有不同的代码。最常用的类型是主动请求为8，主动请求的应答为0。
查询报文类型
我们经常在电视剧里听到这样的话：主帅说，来人哪！前方战事如何，快去派人打探，一有情况，立即通报！

这种是主帅发起的，主动查看敌情，对应ICMP的查询报文类型。例如，常用的ping就是查询报文，是一种主动请求，并且获得主动应答的ICMP协议。所以，ping发的包也是符合ICMP协议格式的，只不过它在后面增加了自己的格式。

对ping的主动请求，进行网络抓包，称为ICMP ECHO REQUEST。同理主动请求的回复，称为ICMP ECHO REPLY。比起原生的ICMP，这里面多了两个字段，一个是标识符。这个很好理解，你派出去两队侦查兵，一队是侦查战况的，一队是去查找水源的，要有个标识才能区分。另一个是序号，你派出去的侦查兵，都要编个号。如果派出去10个，回来10个，就说明前方战况不错；如果派出去10个，回来2个，说明情况可能不妙。
         在选项数据中，ping还会存放发送请求的时间值，来计算往返时间，说明路程的长短。

### 差错报文类型

当然也有另外一种方式，就是差错报文。

主帅骑马走着走着，突然来了一匹快马，上面的小兵气喘吁吁的：报告主公，不好啦！张将军遭遇埋伏，全军覆没啦！这种是异常情况发起的，来报告发生了不好的事情，对应ICMP的差错报文类型。

我举几个ICMP差错报文的例子：终点不可达为3，源抑制为4，超时为11，重定向为5。这些都是什么意思呢？我给你具体解释一下。

第一种是终点不可达。小兵：报告主公，您让把粮草送到张将军那里，结果没有送到。

如果你是主公，你肯定会问，为啥送不到？具体的原因在代码中表示就是，网络不可达代码为0，主机不可达代码为1，协议不可达代码为2，端口不可达代码为3，需要进行分片但设置了不分片位代码为4。

具体的场景就像这样：

网络不可达：主公，找不到地方呀？

主机不可达：主公，找到地方没这个人呀？

协议不可达：主公，找到地方，找到人，口号没对上，人家天王盖地虎，我说12345！

端口不可达：主公，找到地方，找到人，对了口号，事儿没对上，我去送粮草，人家说他们在等救兵。

需要进行分片但设置了不分片位：主公，走到一半，山路狭窄，想换小车，但是您的将令，严禁换小车，就没办法送到了。

第二种是源站抑制，也就是让源站放慢发送速度。小兵：报告主公，您粮草送的太多了吃不完。

第三种是时间超时，也就是超过网络包的生存时间还是没到。小兵：报告主公，送粮草的人，自己把粮草吃完了，还没找到地方，已经饿死啦。

第四种是路由重定向，也就是让下次发给另一个路由器。小兵：报告主公，上次送粮草的人本来只要走一站地铁，非得从五环绕，下次别这样了啊。

差错报文的结构相对复杂一些。除了前面还是IP，ICMP的前8字节不变，后面则跟上出错的那个IP包的IP头和IP正文的前8个字节。

而且这类侦查兵特别恪尽职守，不但自己返回来报信，还把一部分遗物也带回来。

侦察兵：报告主公，张将军已经战死沙场，这是张将军的印信和佩剑。

主公：神马？张将军是怎么死的（可以查看ICMP的前8字节）？没错，这是张将军的剑，是他的剑（IP数据包的头及正文前8字节）。

ping命令执行的时候，源主机首先会构建一个ICMP请求数据包，ICMP数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为 8；另外一个是顺序号，主要用于区分连续ping的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加1。为了能够计算往返时间RTT，它会在报文的数据部分插入发送时间。
然后，由ICMP协议将这个数据包连同地址192.168.1.2一起交给IP层。

目的主机B收到后，待IP层检查后，将有用的信息提取后交给ICMP协议。

主机B会构建一个 ICMP 应答包，应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机A。

在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。

如果不在我们的控制范围内，很多中间设备都是禁止ping的，但是ping不通不代表网络不通。这个时候就要使用telnet，通过其他协议来测试网络是否通

ICMP报文通常封装在IP数据报中，因此它在网络层运作。 ICMP的主要作用是在IP网络中传递诸如错误报告、网络可达性和路由信息等消息，而不是在传输层上建立端到端的数据传输连接。传输层的协议，如TCP和UDP，负责实现端到端的数据传输和可靠性，而网络层的协议（如IP和ICMP）则负责路由和网络通信的控制。


   ### Traceroute命令的作用:
有一个程序Traceroute，是个“大骗子”。它会使用ICMP的规则，故意制造一些能够产生错误的场景。

所以，Traceroute的第一个作用就是故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器,获得其中的ip地址，当然，有的路由器压根不会回这个ICMP。这也是Traceroute一个公网的地址，看不到中间路由的原因。
Traceroute还有一个作用是故意设置不分片，从而确定路径的MTU。要做的工作首先是发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口MTU相等。如果中间遇到窄的关口会被卡住，会发送ICMP网络差错包，类型为“需要进行分片但设置了不分片位”。其实，这是人家故意的好吧，每次收到ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。

  #### 小结:

ICMP相当于网络世界的侦察兵。我讲了两种类型的ICMP报文，一种是主动探查的查询报文，一种异常报告的差错报文；
ping使用查询报文，Traceroute使用差错报文。

## 5 路由器的功能:

网关往往是一个路由器，是一个三层转发的设备。啥叫三层设备？就是把MAC头和IP头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。

很多情况下，人们把网关就叫作路由器。其实不完全准确，而另一种比喻更加恰当：**路由器是一台设备，它有五个网口或者网卡(或网关？)，相当于有五只手，分别连着五个局域网。每只手的IP地址都和局域网的IP地址相同的网段，每只手都是它握住的那个局域网的网关。**
任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下MAC头和IP头，看看，根据自己的路由算法，选择另一只手，加上IP头和MAC头，然后扔出去。

### 路由器工作的大致流程：

#### 转发路由器的工作流程：

MAC地址是一个局域网内才有效的地址。因而，MAC地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于IP地址是否改变。不改变IP地址的网关，我们称为**转发网关；改变IP地址的网关，我们称为NAT网关**。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/d54cb2140c25831d6ec9b3e505796a8f.jpg)

服务器A要访问服务器B。首先，服务器A会思考，192.168.4.101/24和我不是一个网段的，因而需要先发给网关。那网关是谁呢？已经静态配置好了，网关是192.168.1.1。网关的MAC地址是多少呢？发送ARP获取网关的MAC地址，然后发送包。包的内容是这样的：

- 源MAC：服务器A的MAC
- 目标MAC：192.168.1.1这个网口的MAC
- 源IP：192.168.1.101
- 目标IP：192.168.4.101

包到达192.168.1.1这个网口，发现MAC一致，将包收进来，开始思考往哪里转发。

在路由器A中配置了静态路由之后，要想访问192.168.4.101/24，要从192.168.56.1这个口出去，下一跳为192.168.56.2。

于是，路由器A思考的时候，匹配上了这条路由，要从192.168.56.1这个口发出去，发给192.168.56.2，那192.168.56.2的MAC地址是多少呢？路由器A发送ARP获取192.168.56.2的MAC地址，然后发送包。包的内容是这样的：

- 源MAC：192.168.56.1的MAC地址
- 目标MAC：192.168.56.2的MAC地址
- 源IP：192.168.1.101
- 目标IP：192.168.4.101

包到达192.168.56.2这个网口，发现MAC一致，将包收进来，开始思考往哪里转发。

在路由器B中配置了静态路由，要想访问192.168.4.101/24，要从192.168.4.1这个口出去，没有下一跳了(不需要在经过下一个路由器了)。因为我右手这个网卡，就是这个网段的，我是最后一跳了。

于是，路由器B思考的时候，匹配上了这条路由，要从192.168.4.1这个口发出去，发给192.168.4.101。那192.168.4.101的MAC地址是多少呢？路由器B发送ARP获取192.168.4.101的MAC地址，然后发送包。包的内容是这样的：

- 源MAC：192.168.4.1的MAC地址
- 目标MAC：192.168.4.101的MAC地址
- 源IP：192.168.1.101
- 目标IP：192.168.4.101

包到达服务器B，MAC地址匹配，将包收进来。

通过这个过程可以看出，**每到一个新的局域网，MAC都是要变的，但是IP地址都不变。**在IP头里面，不会保存任何网关的IP地址。**所谓的下一跳是，某个IP要将这个IP地址转换为MAC放入MAC头。**

之所以将这种模式比喻称为欧洲十国游，是因为在整个过程中，IP头里面的地址都是不变的。IP地址在三个局域网都可见，在三个局域网之间的网段都不会冲突。在三个网段之间传输包，IP头不改变。

#### NAT路由器的工作流程：

这里遇见的第一个问题是，局域网之间没有商量过，各定各的网段，因而IP段冲突了。最左面大唐的地址是192.168.1.101，最右面印度的地址也是192.168.1.101，如果单从IP地址上看，简直是自己访问自己，其实是大唐的192.168.1.101要访问印度的192.168.1.101。

怎么解决这个问题呢？既然局域网之间没有商量过，你们各管各的，那到国际上，也即中间的局域网里面，就需要使用另外的地址。就像出国，不能用咱们自己的身份证，而要改用护照一样，玄奘西游也要拿着专门取经的通关文牒，而不能用自己国家的身份证。

首先，目标服务器B在国际上要有一个国际的身份，我们给它一个192.168.56.2。在网关B上，我们记下来，国际身份192.168.56.2对应国内身份192.168.1.101。凡是要访问192.168.56.2，都转成192.168.1.101。

于是，源服务器A要访问目标服务器B，要指定的目标地址为192.168.56.2。这是它的国际身份。服务器A想，192.168.56.2和我不是一个网段的，因而需要发给网关，网关是谁？已经静态配置好了，网关是192.168.1.1，网关的MAC地址是多少？发送ARP获取网关的MAC地址，然后发送包。包的内容是这样的：

- 源MAC：服务器A的MAC
- 目标MAC：192.168.1.1这个网口的MAC
- 源IP：192.168.1.101
- 目标IP：192.168.56.2

包到达192.168.1.1这个网口，发现MAC一致，将包收进来，根据目标ip开始思考往哪里转发。

在路由器A中配置了静态路由：要想访问192.168.56.2/24，要从192.168.56.1这个口出去，没有下一跳了，因为我右手这个网卡，就是这个网段的，我是最后一跳了。

于是，路由器A思考的时候，匹配上了这条路由，要从192.168.56.1这个口发出去，发给192.168.56.2。那192.168.56.2的MAC地址是多少呢？路由器A发送ARP获取192.168.56.2的MAC地址。

当网络包发送到中间的局域网的时候，服务器A也需要有个国际身份，因而在国际上，源IP地址也不能用192.168.1.101，需要改成192.168.56.1。发送包的内容是这样的：

- 源MAC：192.168.56.1的MAC地址
- 目标MAC：192.168.56.2的MAC地址
- 源IP：192.168.56.1
- 目标IP：192.168.56.2

包到达192.168.56.2这个网口，发现MAC一致，将包收进来，开始思考往哪里转发。

路由器B是一个NAT网关，它上面配置了，**要访问国际身份192.168.56.2对应国内身份192.168.1.101，于是改为访问192.168.1.101。**

在路由器B中配置了静态路由：要想访问192.168.1.0/24，要从192.168.1.1这个口出去，没有下一跳了，因为我右手这个网卡，就是这个网段的，我是最后一跳了。

于是，路由器B思考的时候，匹配上了这条路由，要从192.168.1.1这个口发出去，发给192.168.1.101。

那192.168.1.101的MAC地址是多少呢？路由器B发送ARP获取192.168.1.101的MAC地址，然后发送包。内容是这样的：

- 源MAC：192.168.1.1的MAC地址
- 目标MAC：192.168.1.101的MAC地址
- 源IP：192.168.56.1
- 目标IP：192.168.1.101

包到达服务器B，MAC地址匹配，将包收进来。

从服务器B接收的包可以看出，源IP为服务器A的国际身份，因而发送返回包的时候，也发给这个国际身份，由路由器A做NAT，转换为国内身份。

从这个过程可以看出，IP地址也会变。这个过程用英文说就是**Network Address Translation**，简称**NAT**。

其实这第二种方式我们经常见，现在大家每家都有家用路由器，家里的网段都是192.168.1.x，所以你肯定访问不了你邻居家的这个私网的IP地址的。所以，当我们家里的包发出去的时候，都被家用路由器NAT成为了运营商的地址了。

很多办公室访问外网的时候，也是被NAT过的，因为不可能办公室里面的IP也是公网可见的，公网地址实在是太贵了，所以一般就是整个办公室共用一个到两个出口IP地址。你可以通过 https://www.whatismyip.com/ 查看自己的出口IP地址。

### 小结:
**如果离开本局域网，就需要经过网关**，网关是路由器的一个网口；

路由器是一个三层设备，里面有如何寻找下一跳的规则；

经过路由器之后MAC头要变，如果IP不变，相当于不换护照的欧洲旅游，如果IP变，相当于换护照的玄奘西行。

### 如何配置路由

#### 静态路由:

静态路由:其实就是在路由器上，配置一条一条规则。这些规则包括：想访问BBS站（它肯定有个网段），从2号口出去，下一跳是IP2；想访问教学视频站（它也有个自己的网段），从3号口出去，下一跳是IP3，然后保存在路由器里。

每当要选择从哪只手抛出去的时候，就一条一条的匹配规则，找到符合的规则，就按规则中设置的那样，从某个口抛出去，找下一跳IPX。

当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为路由表。
一张路由表中会有多条路由规则。每一条规则至少包含这三项信息。

1.目的网络：这个包想去哪儿？
2.出口设备：将包从哪个口扔出去？
3.下一跳网关：下一个路由器的地址。
上一节的例子中，网关上的路由策略就是按照这三项配置信息进行配置的。这种配置方式的一个核心思想是：**根据目的IP地址来配置路由。**

当然，在真实的复杂的网络环境中，除了可以根据目的ip地址配置路由外，还可以根据多个参数来配置路由，这就称为**策略路由**。

可以配置多个路由表，可以根据源IP地址、入口设备、TOS等选择路由表，然后在路由表中查找路由。这样可以使得来自不同来源的包走不同的路由。

如果总是用静态路由，一旦网络结构发生变化，让网络管理员手工修改路由太复杂了，因而需要动态路由算法。



#### 动态路由算法:

##### 1.距离矢量路由算法

每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到达目标路由器，从哪条线出去，另一个是到目标路由器的距离。

每个路由器都是知道全局信息的。每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。每个路由器根据新收集的信息，计算和其他路由器的距离。

问题：1.好消息传得快，坏消息传得慢(记录距离的数会越来越大，直到超过一个阈值，我们才能判定一个路由器真的挂了。)

2.每次发送的时候，要发送整个全局路由表。网络大了，谁也受不了，所以最早的路由协议RIP就是这个算法。它适用于小型网络（小于15跳）。当网络规模都小的时候，没有问题。现在一个数据中心内部路由器数目就很多，因而不适用了。

所以上面的两个问题，限制了距离矢量路由的网络规模。



###### 基于距离矢量路由算法的BGP(外网的路由协议)

外网路由协议（Border Gateway Protocol，简称BGP）

在网络世界，这一个个区域称为自治系统AS（Autonomous System）。

在一个AS内部，有路当然选近的走。但是AS之间，不光远近的问题，还有政策的问题。

自治系统分几种类型。

- Stub AS：对外只有一个连接。这类AS不会传输其他AS的包。例如，个人或者小公司的网络。

- Multihomed AS：可能有多个连接连到其他的AS，但是大多拒绝帮其他的AS传输包。例如一些大公司的网络。

- Transit AS：有多个连接连到其他的AS，并且可以帮助其他的AS传输包。例如主干网。


每个自治系统都有边界路由器，通过它和外面的世界建立联系。
如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/c3bce0ec298138d8e36e6ebf1375d843.jpg)

BGP又分为两类，eBGP和iBGP。自治系统AS间，边界路由器之间使用eBGP广播路由。内部网络也需要访问其他的自治系统。BGP协议使用的算法是路径矢量路由协议（path-vector protocol）。它是距离矢量路由协议的升级版(解决了坏消息传得慢的问题)。通过运行iBGP，边界路由器将BGP学习到的路由导入到内部网络，使得内部的路由器能够找到到达外网目的地的最好的边界路由器。

前面说了距离矢量路由协议的缺点。其中一个是收敛慢。在BGP里面，除了下一跳hop之外，还包括了自治系统AS的路径，从而可以避免坏消息传的慢的问题，也即上面所描述的，B知道C原来能够到达A，是因为通过自己，一旦自己都到达不了A了，就不用假设C还能到达A了。

在路径中将一个自治系统看成一个整体，不区分自治系统内部的路由器，这样自治系统的数目是非常有限的。就像大家都能记住出去玩，从中国出发先到韩国然后到日本，只要不计算细到具体哪一站，就算是发送全局信息，也是没有问题的。



##### 2.链路状态路由算法(基于Dijkstra算法)

这种算法的基本思路是：当一个路由器启动的时候，首先是发现邻居，向邻居say hello，邻居都回复。然后计算和邻居的距离，发送一个echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用Dijkstra算法，找到两点之间的最短路径。
不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和CPU利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。

###### OSPF协议(内网的路由协议)
OSPF（Open Shortest Path First，开放式最短路径优先）协议，基于链路状态路由协议，由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称IGP）。

内部网关协议IGP的重点就是找到最短的路径。在一个组织内部，路径最短往往最优且可能具有多条最短路径(等价路由)。可以在这多个最短路径中进行负载均衡。

有了等价路由，到一个地方去可以有相同的两个路线，可以分摊流量，还可以当一条路不通的时候，走另外一条路。这个在后面我们讲数据中心的网络的时候，一般应用的接入层会有负载均衡LVS。它可以和OSPF一起，实现高吞吐量的接入层设计。

### 小结:
做个总结：
路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略；

动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP协议(外部路由协议)和OSPF协议(内部网关协议)。

## 思考题与GPT回答:
1.路由协议要在路由器之间交换信息，这些信息的交换还需要走路由吗？不是死锁了吗？
路由协议确实需要在路由器之间交换信息，但这些信息通常是通过网络互连的链路传输的，而不是通过路由器自身。
"通过网络互连的链路传输" 意味着路由器之间的通信是通过连接这些路由器的物理或逻辑链路进行的。这些链路可以是物理电缆、光纤、或者逻辑链路（如虚拟专用网络连接）。路由器使用这些链路来交换路由协议信息，以了解网络的拓扑结构和可用路径。

举例来说，如果有两台路由器 A 和 B，它们通过一条物理电缆连接在一起，路由协议信息可以通过这个物理链路传输，以便它们互相了解彼此和相邻网络的状态。这个过程是为了确保路由器在决定如何转发数据包时具有正确的路由表信息。链路传输是路由器之间进行信息交换的基础。


2.路由器之间信息的交换使用什么协议呢？报文格式是什么样呢？

路由器之间的信息交换使用不同的路由协议，具体取决于网络的配置和需求。以下是一些常见的路由协议以及它们的报文格式：

- OSPF (Open Shortest Path First)：OSPF 是一个内部网关协议，它使用Link State Advertisement（LSA）来交换路由信息。 OSPF的报文包括Hello报文、LSA报文和LSU报文。这些报文包含有关网络拓扑和邻居路由器的信息。

- BGP (Border Gateway Protocol)：BGP是一个用于互联网路由的外部网关协议。它使用BGP更新报文来交换路由信息，这些报文包含AS路径、可达性信息等，用于控制路由到不同的IP前缀。

- RIP (Routing Information Protocol)：RIP是一个距离向量协议，它使用RIP消息来交换路由信息。RIP消息包含路由表信息和跳数等。

- EIGRP (Enhanced Interior Gateway Routing Protocol)：EIGRP是思科的专有协议，它使用EIGRP数据包来交换路由信息，包括拓扑表、邻居信息等。

- IS-IS (Intermediate System to Intermediate System)：IS-IS是一种链路状态路由协议，它使用Hello报文和Link State PDUs来交换路由信息。


每个协议的报文格式和交换机制都有细微的差异，以适应不同的网络环境和需求。这些协议的设计旨在确保有效的路由信息传递，以实现网络的正常运行。

## 6 TCP与UDP


### TCP和UDP有哪些区别？
1.TCP是面向连接的，UDP是面向无连接的。
在互通之前，面向连接的协议会先建立连接。所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。

TCP提供可靠交付。通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达。

2.TCP是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP就不会，应用让我发，我就发，管它洪水滔天。

3.TCP其实是一个有状态服务，通俗地讲就是有脑子的，里面精确地记着发送了没有，接收到没有，发送到哪个了，应该接收哪个了，错一点儿都不行。而UDP则是无状态服务。通俗地说是没脑子的，天真无邪的，发出去就发出去了。

### 各层的基础知识
MAC层定义了本地局域网的传输行为，IP层定义了整个网络端到端的传输行为

网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段。

### 6.1 UDP

#### UDP包头是什么样的？

在IP头里面有个8位的协议，这里会存放，数据里面到底是TCP格式还是UDP格式，如果是UDP格式，就能够根据UDP头的格式，从数据里面将它解析出来。

如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/6d1313f51b9dfd7ab454b2cef1cb37bf.jpg)

无论应用程序是使用TCP传数据，还是UDP传数据，都要监听一个端口。正是这个端口，用来区分应用程序。无论是TCP还是UDP包头里面应该有端口号，根据端口号，将数据交给相应的应用程序。

#### UDP的三大特点
1.沟通简单，不需要大量的数据结构、处理逻辑、包头字段。
2.它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也可以传给任何人数据，甚至可以同时传给多个人数据。
3.它不会根据网络的情况进行发包的拥塞控制，无论网络丢包丢成啥样了，它该怎么发还怎么发。

#### UDP的三大使用场景

第一，需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。
我们在第四节讲的DHCP就是基于UDP协议的。一般的获取IP地址都是内网请求，而且一次获取不到IP又没事，过一会儿还有机会。我们讲过PXE可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的TFTP，这个也是基于UDP协议的。在还没有操作系统的时候，客户端拥有的资源很少，不适合维护一个复杂的状态机，而是因为是内网，一般也没啥问题。

第二，不需要一对一沟通，建立连接，而是可以广播的应用。
UDP的不面向连接的功能，可以使得可以承载广播或者多播的协议。DHCP就是一种广播的形式，就是基于UDP协议的，而广播包的格式前面说过了。

对于多播，我们在讲IP地址的时候，讲过一个D类地址，也即组播地址，使用这个地址，可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址的时候，需要发送IGMP包，所在网络的路由器就能收到这个包，知道有个机器上有个进程在监听这个组播地址。当路由器收到这个组播地址的时候，会将包转发给这台机器，这样就实现了跨路由器的组播。

在后面云中网络部分，有一个协议VXLAN，也是需要用到组播，也是基于UDP协议的。

第三，需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。

当前很多应用都是要求低时延的，它们可不想用TCP如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证。例如，如果应用自己觉得，有的包丢了就丢了，没必要重传了，就可以算了，有的比较重要，则应用自己重传，而不依赖于TCP。





#### 基于tcp,udp来自定义自己的网络协议
访问网页和手机APP都是基于HTTP协议的。HTTP协议是基于TCP的，建立连接都需要多次交互，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP可能还会断了重连，也是很耗时的。而且目前的HTTP协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，但是TCP的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。

##### QUIC
而QUIC（全称Quick UDP Internet Connections，快速UDP互联网连接）是Google提出的一种基于UDP改进的通信协议，其目的是降低网络通信的延迟，提供更好的用户互动体验。
QUIC在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。

UDP虽然简单，但它有简单的用法。它可以用在环境简单、需要多播、应用层自己控制传输的地方。例如DHCP、VXLAN、QUIC等。


实时游戏中客户端和服务端要建立长连接，来保证实时传输。但是游戏玩家很多，服务器却不多。由于维护TCP连接需要在内核维护一些数据结构，因而一台机器能够支撑的TCP连接数目是有限的，然后UDP由于是没有连接的，在异步IO机制引入之前，常常是应对海量客户端连接的策略。

异步I/O是计算机操作系统对输入输出的一种处理方式：发起I/O请求的线程不等I/O操作完成，就继续执行随后的代码，I/O结果用其他方式通知发起I/O请求的程序。 与异步I/O相对的是更为常见的“同步（阻塞）I/O”：发起I/O请求的线程不从正在调用的I/O操作函数返回（即被阻塞），直至I/O操作完成。

游戏对实时要求较为严格的情况下，采用自定义的可靠UDP协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。

#### 思考题:
1.都说TCP是面向连接的，在计算机看来，怎么样才算一个连接呢？

在计算机通信中，一个连接通常是通过以下方式定义的：

\1. IP地址和端口号：一个连接由两台计算机之间的IP地址和端口号组合来标识。通常情况下，一个连接由一个源IP地址和端口号与目标IP地址和端口号相组合而成。这四个值唯一标识了一个连接。

\2. 三次握手：在TCP协议中，建立连接通常需要进行三次握手过程。这包括客户端向服务器发送一个连接请求，服务器回应确认，并最终客户端再次确认。这个过程确保了双方都同意建立连接，从而形成一个连接。

\3. 连接状态：在TCP连接建立后，它会有不同的状态，包括已建立（ESTABLISHED）、已关闭（CLOSED）、等待关闭（FIN-WAIT）等。连接状态的管理也是维护连接的一部分。

\4. 数据交换：一旦连接建立，数据可以在双方之间进行传输。连接的生命周期包括数据的传输、错误处理、流控制等。

总的来说，一个TCP连接可以被定义为一对唯一的IP地址和端口号组合，经过三次握手建立，有不同的状态，用于在计算机之间进行可靠的数据传输。

2.你知道TCP的连接是如何建立，又是如何关闭的吗？

**TCP连接建立（三次握手）：**

\1. **第一步**：客户端向服务器发送一个带有SYN（同步序列编号）标志的TCP包，这个包包含了客户端的初始序列号（ISN）。这表示客户端想要建立连接。此时，客户端进入SYN_SENT状态。

\2. **第二步**：服务器接收到客户端的SYN包后，会回应一个带有SYN和ACK（确认）标志的TCP包，也包含服务器的初始序列号。这个包表示服务器接受了连接请求。此时，服务器进入SYN_RECEIVED状态。

\3. **第三步**：客户端收到服务器的响应后，发送一个带有ACK标志的TCP包，确认服务器的确认。这样，连接建立完毕，客户端和服务器都进入ESTABLISHED状态，可以开始数据传输。

**TCP连接关闭（四次挥手）：**

\1. **第一步**：当一方（通常是客户端或服务器）想要关闭连接时，它发送一个带有FIN（结束）标志的TCP包，表示它不再发送数据。此时，发送方进入FIN_WAIT_1状态。

\2. **第二步**：接收方收到带有FIN标志的包后，发送一个带有ACK标志的包，确认收到FIN。此时，发送方进入FIN_WAIT_2状态。接收方也会进入CLOSE_WAIT状态，表示它正在等待应用程序处理完所有数据。

\3. **第三步**：当接收方完成数据处理后，它也发送一个带有FIN标志的包，表示它也要关闭连接。此时，接收方进入LAST_ACK状态，而发送方接收到这个包后进入TIME_WAIT状态，等待一段时间以确保任何延迟的数据都能被处理。

\4. **第四步**：最后，发送方发送一个带有ACK标志的包，确认接收到接收方的FIN包。一旦这个ACK包被接收方确认，连接被完全关闭，发送方退出TIME_WAIT状态。

这个过程确保了TCP连接的可靠关闭，防止数据丢失或重复。

### 6.2 TCP
直播协议多使用RTMP，而这个RTMP协议是基于TCP的。
#### TCP的拥塞控制导致的问题
当网络不好的时候，TCP协议会主动降低发送速度，这对本来当时就卡的看视频来讲是要命的，应该应用层马上重传，而不是主动让步。因而，很多直播应用，都基于UDP实现了自己的视频传输协议。
#### TCP的强顺序问题:
TCP的严格顺序传输要保证前一个收到了，下一个才能确认，如果前一个收不到，下一个就算包已经收到了，在缓存里面，也需要等着。

#### TCP包头格式
如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/a795461effcce686a43f48e094c9adbf.jpg)

各各部分的作用:
1.源端口号和目标端口号:标识通信的两个应用
2.包的序号:解决乱序问题
3.确认序号:解决丢包的问题
4.状态位:SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接
5.窗口大小:通信双方各声明一个窗口，标识自己当前能够的处理能力，进行流量控制

首先，源端口号和目标端口号是不可少的，这一点和UDP是一样的。如果没有这两个端口号。数据就不知道应该发给哪个应用。

接下来是包的序号。为什么要给包编号呢？当然是为了解决乱序的问题。不编好号怎么确认哪个应该先来，哪个应该后到呢。编号是为了解决乱序问题。

还应该有的就是确认序号。发出去的包应该有确认，要不然我怎么知道对方有没有收到呢？如果没有收到就应该重新发送，直到送达。这个可以解决丢包的问题。

接下来有一些状态位。例如SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接等。TCP是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。

还有一个重要的就是窗口大小。TCP要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。
#### TCP的三次握手

三次握手的目的：

- 双方建立连接
- 沟通TCP包的序号的问题

##### 1.双方建立连接

A要向B发起一个连接，当发了第一个请求杳无音信的时候，会有很多的可能性，比如:

1. 第一个请求包丢了
2. 请求绕了弯路，超时了
3. B没有响应这个请求，不想和A连接
4. B已经挂了

A不能确认结果，于是再发，再发。B收到了请求包，就知道了A的存在，并且知道A要和它建立连接。如果B不乐意建立连接，则A会重试一阵后放弃，连接建立失败，没有问题；如果B是乐意建立连接的，则会发送应答包给A。

**一个诡异的现象**就是，A和B原来建立了连接，做了简单通信后，结束了连接。还记得吗？A建立连接的时候，请求包重复发了几次，有的请求包绕了一大圈又回来了，B会认为这也是一个正常的的请求的话，因此建立了连接，可以想象，这个连接不会进行下去，也没有个终结的时候，纯属单相思了。**因而两次握手肯定不行**。**(A请求包的重复发送导致的)**

为什么是三次？
因为三次能够使a与b的消息都是有去有回的。

在大部分情况下，A和B建立了连接之后，A会马上发送数据的，一旦A发送数据，则很多问题都得到了解决。例如A发给B的应答丢了，当A后续发送的数据到达的时候，B可以认为这个连接已经建立(于是能够保证数据的可靠性，不需要三次以上的握手)，或者B压根就挂了，A发送的数据，会报错，说B不可达，A就知道B出事情了。当然你可以说A比较坏，就是不发数据，建立连接后空着。我们在程序设计的时候，可以要求开启**keepalive机制**，即使没有真实的数据包，也有**探活包**。



##### 2.沟通TCP包的序号的问题

A要告诉B，我这面发起的包的序号起始是从哪个号开始的，B同样也要告诉A，B发起的包的序号起始是从哪个号开始的。每个连接都要有不同的序号(通常称为**ISN**（Initial Sequence Number）。这个ISN可以是一个随机数或基于某些算法生成的值。)。这个序号的起始序号是**随着时间变化的**，可以看成一个32位的计数器，每4ms加一。为什么序号不能都从1开始呢？因为这样往往会出现冲突。



双方终于建立了信任，建立了连接。前面也说过，为了维护这个连接，双方都要**维护一个状态机**，在连接建立的过程中，双方的状态变化时序图就像这样。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/666d7d20aa907d8317af3770411f5aa2.jpg)

一开始，客户端和服务端都处于CLOSED状态。先是服务端主动监听某个端口，处于LISTEN状态。然后客户端主动发起连接SYN，之后处于SYN-SENT状态。服务端收到发起的连接，返回SYN，并且ACK客户端的SYN，之后处于SYN-RCVD状态。客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于ESTABLISHED状态，因为它一发一收成功了。服务端收到ACK的ACK之后，处于ESTABLISHED状态，因为它也一发一收了。



#### TCP四次挥手

断开连接的时候的**状态时序图**。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/1f6a5e17b34f00d28722428b7b8ccb11.jpg)

断开的时候，我们可以看到，当A说“不玩了”，就进入FIN_WAIT_1的状态，B收到“A不玩”的消息后，发送知道了，就进入CLOSE_WAIT的状态。

A收到“B说知道了”，就进入FIN_WAIT_2的状态，如果这个时候B直接跑路，则A将**永远在这个状态**。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整tcp_fin_timeout这个参数，设置一个超时时间。

如果B没有跑路，发送了“B也不玩了”的请求到达A时，A发送“知道B也不玩了”的ACK后，从FIN_WAIT_2状态结束，按说A可以跑路了，但是最后的这个ACK万一B收不到呢？则B会重新发一个“B不玩了”，这个时候A已经跑路了的话，B就再也收不到ACK了，因而TCP协议要求A最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果B没收到ACK的话，“B说不玩了”会重发的，A会重新发一个ACK并且足够时间到达B。A直接跑路还有一个问题是，A的端口就直接空出来了，但是B不知道，B原来发过的很多包很可能还在路上，如果A的端口被一个新的应用占用了，这个新的应用会收到上个连接中B发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来B发送的所有的包都死翘翘，再空出端口来。

等待的时间设为2MSL，**MSL**是**Maximum Segment Lifetime**，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文基于是IP协议的，而IP头中有一个TTL域，是IP数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。

还有一个异常情况就是，B超过了2MSL的时间，依然没有收到它发的FIN的ACK，怎么办呢？按照TCP的原理，B当然还会重发FIN，这个时候A再收到这个包之后，A就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送**RST**，B就知道A早就跑了。



#### TCP状态机

将连接建立和连接断开的两个时序状态图综合起来，就是这个著名的TCP的状态机。

TCP连接在传输层有多个状态，通常通过TCP状态机来表示。这些状态包括但不限于：CLOSED（关闭）、LISTEN（监听）、SYN_SENT（已发送同步请求）、SYN_RECEIVED（已接收同步请求）、ESTABLISHED（已建立连接）、FIN_WAIT_1（等待对方的FIN包）、FIN_WAIT_2（等待对方的FIN包，但自己还有数据要发送）、CLOSE_WAIT（等待应用程序关闭连接）、CLOSING（表示同时发送FIN包，等待对方的ACK确认）、TIME_WAIT（等待足够长的时间以确保最后的ACK被接收）、LAST_ACK（等待对方的最后一个ACK）等等。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/dab9f6ee2908b05ed6f15f3e21be88ab.jpg)

在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端A的状态变迁，加粗的虚线是服务端B的状态变迁。

#### 小结

1.TCP包头很复杂，但是主要关注五个问题，
- 顺序问题(包的序号)
- 丢包问题(确认序号)
- 连接维护(状态位)
- 流量控制(窗口大小)
- 拥塞控制

2.连接的建立是经过三次握手，断开的时候四次挥手，一定要掌握的我画的那个状态图。

#### 思考题与gpt回答

1.TCP的连接有这么多的状态，你知道如何在系统中查看某个连接的状态吗？

在Linux或Unix系统中，您可以使用`netstat`或`ss`命令来查看TCP连接的状态：

~~~sh
netstat -tuln    # 列出所有TCP监听状态的连接
netstat -tun     # 列出所有TCP连接的状态
~~~

在Windows系统中，您可以使用`netstat`命令：

~~~sh
netstat -an    # 列出所有TCP连接的状态
~~~

2.这一节仅仅讲了连接维护问题，其实为了维护连接的状态，还有其他的数据结构来处理其他的四个问题，那你知道是什么吗？


维护TCP连接状态涉及许多数据结构和算法，用于处理TCP连接的不同阶段和相关问题。四个主要问题通常是：

1. 连接建立：在此阶段，数据结构用于跟踪客户端和服务器之间的握手过程，以确保双方能够建立连接。这通常涉及使用队列或表来存储等待建立连接的请求，例如SYN队列。
2. 连接维护：一旦连接建立，需要数据结构来跟踪连接的状态，以确保数据正确传输。这包括跟踪序列号、确认号、窗口大小等。通常，连接状态信息会存储在连接表中。
3. 连接释放：当连接关闭时，需要数据结构来管理TCP连接的终止过程。这可能包括等待关闭连接的定时器，以确保所有数据都已传输和确认。连接释放状态也可能包括等待确认的FIN包或ACK包。
4. 连接中断：如果在通信过程中出现错误或连接中断，数据结构用于处理连接恢复或重新建立连接。

这些问题通常由操作系统的TCP/IP协议栈处理，具体的数据结构和算法可能因操作系统而异。一般情况下，连接表、队列、定时器等数据结构和算法在TCP连接的各个阶段都起着重要作用，以确保可靠的数据传输和连接管理。不同的操作系统可能会使用不同的内部数据结构来管理TCP连接状态，但它们都需要有效地处理这四个主要问题。



#### TCP的滑动窗口(rwnd)

为了保证顺序性，每一个包都有一个ID。在建立连接的时候，会商定起始的ID(SYN)是什么，然后按照ID一个个发送。

为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的ID，表示这个ID之前的包都收到了，这种模式称为**累计确认**或者**累计应答**（**cumulative acknowledgment**）。

为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的ID一个个排列，在TCP里，接收端会给发送端报一个窗口的大小，叫**Advertised window**。这个窗口的大小就是已经交代了没做完的加上马上要交代的。超过这个窗口的，接收端做不过来，就不能发送了。

于是，发送端需要保持下面的数据结构。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/16dcd6fb8105a1caa75887b5ffa0bd7b.jpg)

对于接收端来讲，它的缓存里记录的内容要简单一些。

对应的数据结构就像这样。 ﻿﻿![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/f7b1d3bc6b6d8e55f0951e82294c8ba4.jpg)

- MaxRcvBuffer：最大缓存的量；
- LastByteRead之后是已经接收了，但是还没被应用层读取的；

其中第二部分里面，由于收到的包可能不是顺序的，中间就会出现空挡，只有和第一部分连续的才可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。



#### **确认与重传的机制**:

重传的三种方式：

1.**超时触发重传**：即对每一个发送了，但是没有ACK的包，都有设一个定时器，超过了一定的时间，就重新尝试。

但是这个**超时的时间如何评估呢？**这个时间不宜过短，时间必须大于往返时间RTT，否则会引起不必要的重传。也不宜过长，这样超时时间变长，访问就变慢了。估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样RTT，还要采样RTT的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为**自适应重传算法**（**Adaptive Retransmission Algorithm**）。

**超时间隔加倍**：**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。**两次超时，就说明网络环境差，不宜频繁反复发送。**

2.有一个可以**快速重传**的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。例如，接收方发现6、8、9都已经接收了，就是7没来，那肯定是丢了，于是**发送三个6的ACK，要求下一个是7**。客户端收到3个，就会发现7的确又丢了，不等超时，马上重发。

3.**Selective Acknowledgment** （**SACK**）。这种方式需要在TCP头里加一个SACK的东西，可以将缓存的地图发送给发送方。例如可以发送ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是7丢了。



#### 流量控制机制

在对于包的确认中(发送**确认信息**给发送方)，同时**会携带一个滑动窗口(rwnd)的大小**。

如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过在确认信息中修改窗口的大小，甚至可以设置为0，则发送方将暂时停止发送。

发送端的窗口为0时，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

#### 拥塞控制问题 拥塞窗口(cwnd)

滑动窗口rwnd是怕发送方把接收方缓存塞满，而拥塞窗口cwnd，是怕把网络塞满。

水管有粗细，网络有带宽，也即每秒钟能够发送多少数据；水管有长度，端到端有时延。在理想状态下，水管里面水的量=水管粗细 x 水管长度。对于到网络上，通道的容量 = 带宽 × 往返延迟。



TCP的拥塞控制主要来**避免两种现象**，**包丢失**(设备只能每秒处理一个包，多出来的包就会被丢弃)和**超时重传**(在缓存中排队，时延达到一定程度)。一旦出现了这些现象就说明，发送速度太快了，要慢一点。

一条TCP连接开始，cwnd设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd加一，于是一次能够发送两个(1,2,4,8...);一开始为：**指数性的增长**，有一个值ssthresh为65535个字节，当超过这个值的时候，每收到一个确认后，cwnd增加1/cwnd(其实就是加1)，变成了**线性增长。**

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将sshresh设为cwnd/2，将cwnd设为1，重新开始**慢启动**。这真是一旦超时重传，马上回到解放前。

使用**快速重传算法**时。当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，要求下一个包为丢失的包，于是发送端就会快速的重传，不必等待超时再重传。此时cwnd（20）减半为cwnd/2（10），然后sshthresh = cwnd（10），当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/1910bc1a0048d4de7b2128eb0f5dbcd2-1584286484075.jpg)

TCP的拥塞控制主要来避免的两个现象都是有问题的：

**第一个问题**是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。

**第二个问题**是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了**TCP BBR拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/a2b3a5df5eca52e302b75824e4bbbd4c-1584286500709.jpg)

1. TCP的BBR听起来很牛，你知道他是如何达到这个最优点的嘛？
2. 学会了UDP和TCP，你知道如何基于这两种协议写程序吗？这样的程序会有什么坑呢？





## 讲套接字Socket：Talkischeap,showmeth

在讲TCP和UDP协议的时候，我们分客户端和服务端，在写程序的时候，我们也同样这样分。

Socket这个名字很有意思，可以作插口或者插槽讲。虽然我们是写软件程序，但是你可以想象为弄一根网线，一头插在客户端，一头插在服务端，然后进行通信。所以在通信之前，双方都要建立一个Socket。

在网络层，Socket函数需要指定到底是IPv4还是IPv6，分别对应设置为AF_INET和AF_INET6。另外，还要指定到底是TCP还是UDP。还记得咱们前面讲过的，TCP协议是基于数据流的，所以设置为SOCK_STREAM，而UDP是基于数据报的，因而设置为SOCK_DGRAM。

两端创建了Socket之后，接下来的过程中，TCP和UDP稍有不同，我们先来看TCP。

TCP的服务端要先监听一个端口，一般是先调用bind函数，给这个Socket赋予一个IP地址和端口。为什么需要端口呢？要知道，你写的是一个应用程序，当一个网络包来的时候，内核要通过TCP头里面的这个端口，来找到你这个应用程序，把包给你。为什么要IP地址呢？有时候，一台机器会有多个网卡，也就会有多个IP地址，你可以选择监听所有的网卡，也可以选择监听一个网卡，这样，只有发给这个网卡的包，才会给你。

当服务端有了IP和端口号，就可以调用listen函数进行监听。在TCP的状态图里面，有一个listen状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。

在内核中，为每个Socket维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于established状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于syn_rcvd的状态。

接下来，服务端调用accept函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。

在服务端等待的时候，客户端可以通过connect函数发起连接。先在参数中指明要连接的IP地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的accept就会返回另一个Socket。

这是一个经常考的知识点，就是监听的Socket和真正用来传数据的Socket是两个，一个叫作监听Socket，一个叫作已连接Socket。

连接建立成功之后，双方开始通过read和write函数来读写数据，就像往一个文件流里面写东西一样。

如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/77d5eeb659d5347874bda5e8f711f692.jpg)

### 小结:
1.你需要记住TCP和UDP的Socket的编程中，客户端和服务端都需要调用哪些函数；

2.写一个能够支撑大量连接的高并发的服务端不容易，需要多进程、多线程，而epoll机制能解决C10K问题。


## 14 讲HTTP协议：看个新闻原来这么麻烦
### 1.HTTP请求的准备:
访问www.163.com这个统一资源定位符时，
浏览器会将www.163.com这个域名发送给DNS服务器，让它解析为IP地址。HTTP是基于TCP协议的，接下来会先建立TCP连接(TCP的三次握手)，建立了连接以后，浏览器就要发送HTTP的请求。

目前使用的HTTP协议大部分都是1.1。在1.1的协议里面，默认是开启了Keep-Alive的，这样建立的TCP连接，就可以在多次请求中复用。

### 2.HTTP请求的构建
http请求的格式就像这样。

如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/10ff27d1032bf32393195f23ef2f9874.jpg)

HTTP的报文大概分为三大部分。第一部分是请求行，第二部分是请求的首部，第三部分才是请求的正文实体。

2.1请求行  方法有几种类型:

对于访问网页来讲，最常用的类型就是GET。顾名思义，GET就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如说返回一个JSON字符串，到底要返回什么，是由服务器端的实现决定的。

另外一种类型叫做POST。它需要主动告诉服务端一些信息，而非获取。要告诉服务端什么呢？一般会放在正文里面。正文可以有各种各样的格式。常见的格式也是JSON。

还有一种类型叫PUT，就是向指定资源位置上传最新内容。但是，HTTP的服务器往往是不允许上传文件的，所以PUT和POST就都变成了要传给服务器东西的方法。在实际使用过程中，这两者还会有稍许的区别。POST往往是用来创建一个资源的，而PUT往往是用来修改一个资源的。

再有一种常见的就是DELETE。这个顾名思义就是用来删除资源的。

2.2 第二部分：首部字段
请求行下面就是我们的首部字段。首部是key value，通过冒号分隔。

Accept-Charset，表示客户端可以接受的字符集。防止服务器传过来的是另外的字符集，从而导致出现乱码。

Content-Type是指正文的格式。例如，我们进行POST的请求，如果正文是JSON，那么我们就应该将这个值设置为JSON。

对于高并发场景下的系统，在真正的业务逻辑之前，都需要有个接入层，将这些静态资源的请求拦在最外面。
如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/c81af7a52305f7de27e32e34a02d0eac.jpg)

Nginx这一层，它如何处理HTTP协议呢？对于静态资源，有Vanish缓存层。当缓存过期的时候，才会访问真正的Tomcat应用集群。

在HTTP头里面，Cache-control是用来控制缓存的。当客户端发送的请求中包含max-age指令时，如果判定缓存层中，资源的缓存时间数值比max-age指定时间的数值小，那么表示客户端可以接受缓存的资源；当指定max-age值为0，那么缓存层通常需要将请求转发给应用集群。

If-Modified-Since也是一个关于缓存的。也就是说，如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回“304 Not Modified”的响应，那客户端就不用下载了，也会节省带宽。

到此为止，我们仅仅是拼凑起了HTTP请求的报文格式，接下来，浏览器会把它交给下一层传输层。怎么交给传输层呢？其实也无非是用Socket这些东西，只不过用的浏览器里，这些程序不需要你自己写，有人已经帮你写好了。

### 3 HTTP请求的发送

HTTP协议是基于TCP协议的，所以它使用面向连接的方式发送请求，通过stream二进制流的方式传给对方。当然，到了TCP层，它会把二进制流变成一个的报文段发送给服务器。

在发送给每个报文段的时候，都需要对方有一个回应ACK，来保证报文可靠地到达了对方。如果没有回应，那么TCP这一层会进行重新传输，直到可以到达。同一个包有可能被传了好多次，但是HTTP这一层不需要知道这一点，因为是TCP这一层在埋头苦干。

TCP层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到IP头里面，交给IP层进行传输。

IP层需要查看目标地址和自己是否是在同一个局域网。如果是，就发送ARP协议来请求这个目标地址对应的MAC地址，然后将源MAC和目标MAC放入MAC头，发送出去即可；如果不在同一个局域网，就需要发送到网关，还要需要发送ARP协议，来获取网关的MAC地址，然后将源MAC和网关MAC放入MAC头，发送出去。

网关收到包发现MAC符合，取出目标IP地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的MAC地址，将包发给下一跳路由器。

这样路由器一跳一跳终于到达目标的局域网。这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送ARP，获得这个目标地址的MAC地址，将包发出去。

目标的机器发现MAC地址符合，就将包收起来；发现IP地址符合，根据IP头中协议项，知道自己上一层是TCP协议，于是解析TCP的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个ACK，如果不是就丢弃。

TCP头里面还有端口号，HTTP的服务器正在监听这个端口号。于是，目标机器自然知道是HTTP服务器这个进程想要这个包，于是将包发给HTTP服务器。HTTP服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。

### 4 HTTP响应的构建

HTTP的返回报文也是有一定格式的。
状态行，首部，实体
这也是基于HTTP 1.1的。

如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/1c2cfd4326d0dfca652ac8501321fac1.jpg)

首部的key value有:

Retry-After表示，告诉客户端应该在多长时间以后再次尝试一下。“503错误”是说“服务暂时不再和这个值配合使用”。

Content-Type，表示返回的是HTML，还是JSON。

构造好了返回的HTTP报文，接下来就是把这个报文发送出去。还是交给Socket去发送，还是交给TCP层，让TCP层将返回的HTML，也分成一个个小的段，并且保证每个段都可靠到达。

这些段加上TCP头后会交给IP层，然后把刚才的发送过程反向走一遍。虽然两次不一定走相同的路径，但是逻辑过程是一样的，一直到达客户端。

客户端发现MAC地址符合、IP地址符合，于是就会交给TCP层。根据序列号看是不是自己要的报文段，如果是，则会根据TCP头中的端口号，发给相应的进程。这个进程就是浏览器，浏览器作为客户端也在监听某个端口。

当浏览器拿到了HTTP的报文。发现返回“200”，一切正常，于是就从正文中将HTML拿出来。HTML是一个标准的网页格式。浏览器只要根据这个格式，展示出一个绚丽多彩的网页。

这就是一个正常的HTTP请求和返回的完整过程。

### 5 HTTP 2.0

pipeline模式:用多条TCP连接来实现并行请求与响应。

HTTP 1.1在应用层以纯文本的形式进行通信。每次通信都要带完整的HTTP的头，而且不考虑pipeline模式的话，每次的过程总是像上面描述的那样一去一回。这样在实时性、并发性上都存在问题。

HTTP 2.0通过头压缩、分帧、二进制编码、多路复用等技术提升性能；

HTTP 2.0会对HTTP的头进行一定的压缩，将原来每次都要携带的大量key value在两端建立一个索引表，对相同的头只发送索引表中的索引。
另外，HTTP 2.0协议将一个TCP的连接中，切分成多个流，每个流都有自己的ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。
HTTP 2.0还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有Header帧，用于传输Header内容，并且会开启一个新的流。再就是Data帧，用来传输正文实体。多个Data帧属于同一个流。

通过这两种机制，HTTP 2.0的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。



假设我们的一个页面要发送三个独立的请求，一个获取css，一个获取js，一个获取图片jpg。如果使用HTTP 1.1就是串行的，但是如果使用HTTP 2.0，就可以在一个连接里，客户端和服务端都可以同时发送多个请求或回应，而且不用按照顺序一对一对应。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/0bc51f8f887aae04ef89a1a88cb5a17a.jpg)

HTTP 2.0其实是将三个请求变成三个流，将数据分成帧，乱序发送到一个TCP连接中。

img

HTTP 2.0成功解决了HTTP 1.1的队首阻塞问题，同时，也不需要通过HTTP 1.x的pipeline机制用多条TCP连接来实现并行请求与响应；减少了TCP连接数对服务器性能的影响，同时将页面的多个数据css、js、 jpg等通过一个数据链接进行传输，能够加快页面组件的传输速度。

## 15 讲HTTPS协议：点外卖的过程原来这么复杂

加密分为两种方式一种是对称加密，一种是非对称加密。

在对称加密算法中，加密和解密使用的密钥是相同的。也就是说，加密和解密使用的是同一个密钥。因此，对称加密算法要保证安全性的话，密钥要做好保密。只能让使用的人知道，不能对外公开。

在非对称加密算法中，加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。

因为对称加密算法相比非对称加密算法来说，效率要高得多，性能也好，所以交互的场景下多用对称加密。

### 6 HTTPS的工作模式

因为非对称加密在性能上不如对称加密，于是https将两者结合起来
HTTPS协议的总体思路:
非对称加密的公钥、私钥主要用于传输对称加密的秘钥，而真正的双方大数据量的通信都是通过对称加密进行的。

### 小结:
加密分对称加密和非对称加密。对称加密效率高，但是解决不了密钥传输问题；非对称加密可以解决这个问题，但是效率不高。
非对称加密需要通过证书和权威机构来验证公钥的合法性。
HTTPS是综合了对称加密和非对称加密算法的HTTP协议。既保证传输安全，也保证传输效率。

### 思考题:
2对于视频播放，通常会使用HTTP Live Streaming（HLS）或者Dynamic Adaptive Streaming over HTTP（DASH）等流媒体协议。这些协议允许按需传输数据，适应网络条件，提供更好的用户体验。它们允许分块传输，并根据网络状况自动选择最佳的视频质量。

## 16 讲流媒体协议：如何在直播里看到美女帅哥？
### 1 视频与编码
视频是什么？我说，其实就是快速播放一连串连续的图片。

每一张图片，我们称为一帧。只要每秒钟帧的数据足够多，也即播放得足够快。比如每秒30帧，以人的眼睛的敏感程度，是看不出这是一张张独立的图片的，这就是我们常说的帧率（FPS）。

每一张图片，都是由像素组成的，假设为1024*768（这个像素数不算多）。每个像素由RGB组成，每个8位，共24位，3字节。

我们来算一下，每秒钟的视频有多大？

30帧 × 1024 × 768 × 24 = 566,231,040Bits = 70,778,880Bytes

如果一分钟呢？4,246,732,800Bytes，已经是4个G了。

编码，就是看如何用尽量少的Bit数保存视频，使播放的时候画面看起来仍然很精美。编码是一个压缩的过程。经过编码之后，生动活泼的一帧一帧的图像，就变成了一串串让人看不懂的二进制，这个二进制可以放在一个文件里面，按照一定的格式保存起来，这就是视频后缀 mp4,mkv...。

之所以能够对视频流中的图片进行压缩，因为视频和图片有这样一些特点。

空间冗余：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整地保存，可以隔几个保存一个，中间的用算法计算出来。
时间冗余：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。
视觉冗余：人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。
编码冗余：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似霍夫曼编码（Huffman Coding）的思路。
总之，用于编码的算法非常复杂，而且多种多样，但是编码过程其实都是类似的。

### 2 直播过程中视频的传输:
视频编码为二进制后也可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。
2.1 服务器从主播处接流
网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流，这个过程称为接流。
2.2 服务器接流后进行处理
服务端接到视频流之后，可以对视频流进行一定的处理，例如转码，也即从一个编码格式，转成另一种格式。因为观众使用的客户端千差万别，要保证他们都能看到直播。

2.3 观众从服务器拉流
流处理完毕之后，就可以等待观众的客户端来请求这些视频流。观众的客户端请求的过程称为拉流。

如果有非常多的观众，同时看一个视频直播，那都从一个服务器上拉流，压力太大了，因而需要一个视频的分发网络，将视频预先加载到就近的边缘节点，这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。

当观众的客户端将视频流拉下来之后，就需要进行解码，也即通过上述过程的逆过程，将一串串看不懂的二进制，再转变成一帧帧生动的图片，在客户端播放出来，这样你就能看到美女帅哥啦。

整个直播过程，可以用这个的图来描述。
如图:

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/e4d4b538c434ec0eade37028a34391f8.jpg)

### 3 分发网络与RTMP协议
大量观看直播的观众可以通过RTMP协议从流媒体服务器上拉取，但是这么多的用户量，都去同一个地方拉取，服务器压力会很大，而且用户分布在全国甚至全球，如果都去统一的一个地方下载，也会时延比较长，需要有分发网络。

分发网络分为中心和边缘两层。边缘层服务器部署在全国各地及横跨各大运营商里，和用户距离很近。中心层是流媒体服务集群，负责内容的转发。智能负载均衡系统，根据用户的地理位置信息，就近选择边缘服务器，为用户提供推/拉流服务。中心层也负责转码服务，例如，把RTMP协议的码流转换为HLS码流。如图:

### 4 小结:

视频名词比较多，编码两大流派达成了一致，都是通过时间、空间的各种算法来压缩数据；

压缩好的数据，为了传输组成一系列NALU，按照帧和片依次排列；

排列好的NALU，在网络传输的时候，要按照RTMP包的格式进行包装，RTMP的包会拆分成Chunk进行传输；

推送到流媒体集群的视频流经过转码和分发，可以被客户端通过RTMP协议拉取，然后组合为NALU，解码成视频格式进行播放。

## 17 讲P2P协议：我下小电影，99%急死你

如果你想下载一个电影，一般会通过什么方式呢？

### 1 FTP协议

当然，最简单的方式就是通过HTTP进行下载。还有种下载文件的方式，就是通过FTP，也即文件传输协议。FTP采用两个TCP连接来传输一个文件:
1.控制连接：服务器以被动的方式，打开众所周知用于FTP的端口21，客户端则主动发起连接。该连接将命令从客户端传给服务器，并传回服务器的应答。常用的命令有：list——获取文件目录；reter——取一个文件；store——存一个文件。
2.数据连接：每当一个文件在客户端与服务器之间传输时，就创建一个数据连接。

FTP的两种工作模式

每传输一个文件，都要建立一个全新的数据连接。FTP有两种工作模式，分别是主动模式（PORT）和被动模式（PASV），这些都是站在FTP服务器的角度来说的。

主动模式下，客户端随机打开一个大于1024的端口N，向服务器的命令端口21发起连接，同时开放N+1端口监听，并向服务器发出 “port N+1” 命令，由服务器从自己的数据端口20，主动连接到客户端指定的数据端口N+1。

被动模式下，当开启一个FTP连接时，客户端打开两个任意的本地端口N（大于1024）和N+1。第一个端口连接服务器的21端口，提交PASV命令。然后，服务器会开启一个任意的端口P（大于1024），返回“227 entering passive mode”消息，里面有FTP服务器开放的用来进行数据传输的端口。客户端收到消息取得端口号之后，会通过N+1号端口连接服务器的端口P，然后在两个端口之间进行数据传输。



### 2 p2p协议

无论是HTTP的方式，还是FTP的方式，都有一个比较大的缺点，就是**难以解决单一服务器的带宽压力**， 因为它们使用的都是传统的**客户端服务器的方式**。**P2P**就是**peer-to-peer**。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。这些设备我们姑且称为peer。想要下载一个文件的时候，你只要得到那些已经存在了文件的peer，并和这些peer之间，建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。一旦下载了文件，你也就成为peer中的一员，你旁边的那些机器，也可能会选择从你这里下载文件。自己从别人那里下载，同时也提供给其他人下载。这种方式，参与的人越多，下载速度越快。

使用P2P软件的时候，例如BitTorrent，往往能够看到，既有下载流量，也有上传的流量，也即你自己也加入了这个P2P的网络中。

当你想下载一个文件的时候，怎么知道哪些peer有这个文件呢？

这就用到**种子**啦，也即咱们比较熟悉的**.torrent文件**。.torrent文件由两部分组成，分别是：**announce**（**tracker URL**）和**文件信息**。

**p2p下载的大致流程**：

下载时，BT客户端首先解析.torrent文件，得到tracker地址，然后连接tracker服务器。tracker服务器回应下载者的请求，将其他下载者（包括发布者）的**IP提供给下载者**。下载者再连接其他下载者，根据.torrent文件，两者分别告知对方自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，并分散了单个线路上的数据流量，因此减轻了服务器的负担。

下载者每得到一个块，需要算出下载块的Hash验证码，并与.torrent文件中的对比。如果一样，则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容的**准确性问题**。

从这个过程也可以看出，这种方式**特别依赖tracker**。tracker需要收集下载者信息的服务器，并将此信息提供给其他下载者，使下载者们相互连接起来，传输数据。虽然下载的过程是非中心化的，但是加入这个P2P网络的时候，都需要借助tracker中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源。

所以，这种工作方式有一个**弊端**，一旦tracker服务器出现故障或者线路遭到屏蔽，BT工具就无法正常工作了。

## 18 讲DNS协议：网络世界的地址簿

**DNS服务器，一定要设置成高可用、高并发和分布式的**。

于是，就有了这样**树状的层次结构**。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/59f79cba26904ff721aabfcdc0c27da6.jpg)﻿

- 根DNS服务器 ：返回顶级域DNS服务器的IP地址
- 顶级域DNS服务器：返回权威DNS服务器的IP地址
- 权威DNS服务器 ：返回相应主机（域名）的IP地址

### DNS解析流程

为了提高DNS的解析性能，很多网络都会就近部署**DNS缓存服务器**。于是，就有了以下的**DNS解析流程**。

0. 首先会查询本地的DNS缓存，即hosts文件，查看是否记录有对应域名的ip地址。

1. 如果hosts中没有，电脑客户端会发出一个DNS请求，问www.163.com的IP是啥啊，并发给**本地域名服务器 (本地DNS)**。那本地域名服务器 (本地DNS) 是什么呢？如果是通过DHCP配置，本地DNS由你的**网络服务商（ISP）**，如电信、移动等自动分配，它通常就在你网络服务商的某个机房。
2. 本地DNS收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应IP地址的**大表格**。如果能找到 www.163.com，它直接就返回IP地址。如果没有，本地DNS会去问它的**根域名服务器**，根域名服务器是最高层次的，全球共有13套。它**不直接用于域名解析**，但能**指明一条道路**。
3. 根DNS收到来自本地DNS的请求，发现后缀是 .com，说明这个域名是由.com区域管理，于是根DNS指明**顶级域名服务器**的地址
4. 本地DNS转向问顶级域名服务器，顶级域名服务器就是大名鼎鼎的比如 .com、.net、 .org这些一级域名，它负责管理二级域名，比如 163.com，所以它能**提供一条更清晰的方向**。
5. 顶级域名服务器指明负责 www.163.com 区域的**权威DNS服务器**的地址。
6. 本地DNS转向问权威DNS服务器，163.com的权威DNS服务器，它是域名解析结果的原出处。权威DNS服务器会查询后将对应的IP地址X.X.X.X告诉本地DNS。
7. 本地DNS再将IP地址返回客户端，客户端和目标建立连接。

至此，我们完成了DNS的解析过程。现在总结一下，整个过程我画成了一个图。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/ff7e8f824ebd1f7e16ef5d70cd79bdf2.jpg)

### 负载均衡

**在这个基础上，我们可以再进一步。例如，某个应用要访问另外一个应用，如果配置另外一个应用的IP地址，那么这个访问就是一对一的。但是当被访问的应用撑不住的时候，我们其实可以部署多个。但是，访问它的应用，如何在多个之间进行负载均衡？只要配置成为域名就可以了。在域名解析的时候，我们只要配置策略，这次返回第一个IP，下次返回第二个IP，就可以实现负载均衡了。**



**为了保证我们的应用高可用，往往会部署在多个机房，每个地方都会有自己的IP地址。当用户访问某个域名的时候，这个IP地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要在DNS服务器里面，将这个数据中心对应的IP地址删除，就可以实现一定的高可用。**



当一个客户端要访问object.yourcompany.com的时候，需要将域名转换为IP地址进行访问，所以它要请求本地DNS解析器。
本地DNS解析器先查看看本地的缓存是否有这个记录。如果有则直接使用，因为上面的过程太复杂了，如果每次都要递归解析，就太麻烦了。
如果本地无缓存，则需要请求本地的DNS服务器。
本地的DNS服务器一般部署在你的数据中心或者你所在的运营商的网络中，本地DNS服务器也需要看本地是否有缓存，如果有则返回，因为它也不想把上面的递归过程再走一遍。
至 7. 如果本地没有，本地DNS才需要递归地从根DNS服务器，查到.com的顶级域名服务器，最终查到 yourcompany.com 的权威DNS服务器，给本地DNS服务器，权威DNS服务器按说会返回真实要访问的IP地址。

对于不需要做全局负载均衡的简单应用来讲，yourcompany.com的权威DNS服务器可以直接将 object.yourcompany.com这个域名解析为一个或者多个IP地址，然后客户端可以通过多个IP地址，进行简单的轮询，实现简单的负载均衡。
### 小结:
DNS可以通过域名查地址，因为域名服务器是按照树状结构组织的，因而域名查找是使用递归的方法，并通过缓存的方式增强性能；
在域名和IP的映射过程中，给了应用基于域名做负载均衡的机会，可以是简单的负载均衡，也可以根据地址和运营商做全局的负载均衡。

DNS的两项功能，第一是根据名称查到具体的地址，另外一个是可以针对多个地址做负载均衡，而且可以在多个地址中选择一个距离你近的地方访问。

### 传统DNS存在哪些问题？

1.域名缓存问题
1.1缓存的数据老旧问题
1.2 有的运营商会把一些静态页面，缓存到本运营商的服务器内，这样用户请求的时候，就不用跨运营商进行访问，这样既加快了速度，也减少了运营商之间流量计算的成本。在域名解析的时候，不会将用户导向真正的网站，而是指向这个缓存的服务器。
1.3 本地的缓存，往往使得全局负载均衡失败，因为上次进行缓存的时候，缓存中的地址不一定是这次访问离客户最近的地方，如果把这个地址返回给客户，那肯定就会绕远路。
2.域名转发问题:
如果是A运营商的客户，访问自己运营商的DNS服务器，如果A运营商去权威DNS服务器查询的话，权威DNS服务器知道你是A运营商的，就返回给一个部署在A运营商的网站地址 ip？，这样针对相同运营商的访问，速度就会快很多。

但是A运营商偷懒，将解析的请求转发给B运营商，B运营商去权威DNS服务器查询的话，权威服务器会误认为，你是B运营商的，那就返回给你一个在B运营商的网站地址 ip？吧，结果客户的每次访问都要跨运营商，速度就会很慢。
3.出口NAT问题
一旦做了网络地址的转换，权威的DNS服务器，就没办法通过这个地址，来判断客户到底是来自哪个运营商，而且极有可能因为转换过后的地址，误判运营商，导致跨运营商的访问。
4.域名更新问题
dns缓解过期时间问题。
TTL与DNS TTL有区别。 二者都是生存时间，前者指ICMP包的转发次数（跳数），后者指域名解析信息在DNS中的存在时间。
5.解析延迟问题

DNS的查询过程需要递归遍历多个DNS服务器，才能获得最终的解析结果，这会带来一定的时延，甚至会解析超时。

## 20 讲CDN：你去小卖部取过快递么？

### 1.CDN的分发系统的架构

在数据中心里部署几台机器，形成一个缓存的集群来缓存部分数据，那么用户访问数据的时候，就可以就近访问了，这些分布在各个地方的各个数据中心的节点，就称为边缘节点。
在边缘节点之上，有区域节点，规模就要更大，缓存的数据会更多，命中的概率也就更大。在区域节点之上是中心节点，规模更大，缓存数据更多。如果还不命中，就只好回源网站访问了。这就是CDN的分发系统的架构。CDN系统的缓存，也是一层一层的，能不访问后端真正的源，就不打扰它。

### 2.客户端如何找到相应的边缘节点进行访问呢？

在没有CDN的情况下，用户向浏览器输入www.web.com这个域名，客户端访问本地DNS服务器的时候，如果本地DNS服务器有缓存，则返回网站的地址；如果没有，递归查询到网站的权威DNS服务器，这个权威DNS服务器是负责web.com的，它会返回网站的IP地址。本地DNS服务器缓存下IP地址，将IP地址返回，然后客户端直接访问这个IP地址，就访问到了这个网站。

然而有了CDN之后，情况发生了变化。在web.com这个权威DNS服务器上，会设置一个CNAME别名，指向另外一个域名 www.web.cdn.com，返回给本地DNS服务器。

当本地DNS服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是web.com的权威DNS服务器了，而是web.cdn.com的权威DNS服务器，这是CDN自己的权威DNS服务器。在这个服务器上，还是会设置一个CNAME，指向另外一个域名，也即CDN网络的全局负载均衡器。

接下来，本地DNS服务器去请求CDN的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：

根据用户IP地址，判断哪一台服务器距用户最近；
用户所处的运营商；
根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需的内容；
查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。
基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的IP地址。

本地DNS服务器缓存这个IP地址，然后将IP返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

### 小结

CDN和电商系统的分布式仓储系统一样，分为中心节点、区域节点、边缘节点，获取数据时从离用户最近的位置读取缓存中的数据。
CDN最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据，这时候要注意使用防盗链。它也支持动态数据的缓存。

## 22 讲VPN：朝中有人好做官

### 1 VPN

全名Virtual Private Network，虚拟专用网，就是利用开放的公众网络，建立专用数据传输通道，将远程的分支机构、移动办公人员等连接起来。

### 2 ATM协议:
因为IP网络从设计的时候，就认为是不可靠的，所以即使同一个连接，也可能选择不同的道路，这样的好处是，一条道路崩溃的时候，总有其他的路可以走。当然，带来的代价就是，不断的路由查找，效率比较差。

和IP对应的另一种技术称为ATM。这种协议和IP协议的不同在于，它是面向连接的。你可以说TCP也是面向连接的啊。这两个不同，ATM和IP是一个层次的，和TCP不是一个层次的。

另外，TCP所谓的面向连接，是不停地重试来保证成功，其实下层的IP还是不面向连接的，丢了就丢了。ATM是传输之前先建立一个连接，形成一个虚拟的通路，一旦连接建立了，所有的包都按照相同的路径走，不会分头行事。
好处是不需要每次都查路由表的，虚拟路径已经建立，打上了标签，后续的包傻傻的跟着走就是了，不用像IP包一样，每个包都思考下一步怎么走，都按相同的路径走，这样效率会高很多。

但是一旦虚拟路径上的某个路由器坏了，则这个连接就断了，什么也发不过去了，因为其他的包还会按照原来的路径走，都掉坑里了，它们不会选择其他的路径走。

ATM技术虽然没有成功，但其屏弃了繁琐的路由查找，改为简单快速的标签交换，将具有全局意义的路由表改为只有本地意义的标签表，这些都可以大大提高一台路由器的转发功力。

### 3 小结:
完全基于软件的IPsec VPN可以保证私密性(对称加密，因特网密钥交换（IKE，Internet Key Exchange）协议)、完整性(哈希校验)、真实性、简单便宜，但是性能稍微差一些；

## 24 讲云中网络：自己拿地成本高，购买公寓更灵活

虚拟机采用的是**软件模拟硬件**的方式。

例如，多个虚拟机轮流使用物理CPU，内存也是使用虚拟内存映射的方式，最终映射到物理内存上。硬盘在一块大的文件系统上创建一个N个G的文件，作为虚拟机的硬盘。

### 虚拟网卡的原理

如何将虚拟机的网络和物理机的网络连接起来？

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/9a257afaa9c8a158a5a99e2df00dcf7e.jpg)

首先，虚拟机要有一张网卡。在数据中心里面，有一种开源技术qemu-kvm，对于qemu-kvm来说，这是通过Linux上的一种TUN/TAP技术来实现的。

虚拟机是物理机上跑着的一个软件。这个软件可以像其他应用打开文件一样，打开一个称为TUN/TAP的Char Dev（字符设备文件）。打开了这个字符设备文件之后，在物理机上就能看到一张虚拟TAP网卡。

虚拟化软件作为“骗子”，会将打开的这个文件，在虚拟机里面虚拟出一张网卡，让虚拟机里面的应用觉得它们真有一张网卡。于是，所有的网络包都往这里发。

当然，网络包会到虚拟化软件这里。它会将网络包转换成为文件流，写入字符设备，就像写一个文件一样。内核中TUN/TAP字符设备驱动会收到这个写入的文件流，交给TUN/TAP的虚拟网卡驱动。这个驱动将文件流再次转成网络包，交给TCP/IP协议栈，最终从虚拟TAP网卡发出来，成为标准的网络包。

就这样，几经转手，数据终于从虚拟机里面，发到了虚拟机外面。

### 共享与互通问题（网络问题）

一台物理机上有多个虚拟机，有多个虚拟网卡，这些虚拟网卡如何连在一起，进行相互访问，并且可以访问外网呢？

#### 1 host-only的网络

其实就是把两个虚拟机连到一个br0虚拟网桥上，而且不考虑访问外部的场景，只要虚拟机之间能够相互访问就可以了。

在物理机上，应该有一个虚拟的交换机，在Linux上有一个命令叫作brctl，可以创建虚拟的网桥brctl addbr br0。创建出来以后，将两个虚拟机的**虚拟网卡，都连接到虚拟网桥**brctl addif br0 tap0上，这样**将两个虚拟机配置相同的子网网段，两台虚拟机就能够相互通信了**。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/6976194513a8ec9066c1dd26e7b07ca1.jpg)

那这些虚拟机如何连外网呢？在桌面虚拟化软件上面，我们能看到以下选项。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/ee3424547c32433e04fb174fdbaa9924.jpg)



如果要访问外部，往往有两种方式。

#### 2 桥接网络

如果在桌面虚拟化软件上选择桥接网络，则在你的笔记本电脑上，就会形成下面的结构。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/9347b67409e26924ea9358f052f2e9f4.jpg)

每个虚拟机都会有虚拟网卡，在你的笔记本电脑上，会发现多了几个网卡，其实是虚拟交换机。这个虚拟交换机将虚拟机连接在一起。在桥接模式下，物理网卡也连接到这个虚拟交换机上。

如果使用桥接网络，当你登录虚拟机里看IP地址的时候会发现，你的虚拟机的地址和你的笔记本电脑的，以及你旁边的同事的电脑的**网段是一个网段**。这是为什么呢？这其实**相当于将物理机和虚拟机放在同一个网桥上，相当于这个网桥上有三台机器，是一个网段的**，全部打平了。我将图画成下面的样子你就好理解了。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/e55e9a85106d9086e51cd649a182d707.jpg)

在数据中心里面，采取的也是类似的技术，只不过都是Linux，在每台机器上都创建网桥br0，虚拟机的网卡都连到br0上，物理网卡也连到br0上，所有的br0都通过物理网卡出来连接到物理交换机上。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/a859bb918ab4ca53c3542a6b18884ec0.jpg)

同样我们换一个角度看待这个拓扑图。同样是将网络打平，虚拟机会和你的物理网络具有相同的网段。

![img](https://lianglianglee.com/%e6%9e%81%e5%ae%a2%e6%97%b6%e9%97%b4/assets/a145ea19a844b3e38834efbf0f4cedb7.jpg)

在这种方式下，不但解决了同一台机器的互通问题，也解决了跨物理机的互通问题，因为都在一个二层网络里面，彼此用相同的网段访问就可以了。但是当规模很大的时候，会存在问题。

在一个**二层网络**里面，最大的问题是**广播**。一个数据中心的物理机已经很多了，广播已经非常严重，需要通过VLAN进行划分。如果使用了虚拟机，假设一台物理机里面创建10台虚拟机，全部在一个二层网络里面，那广播就会很严重，所以除非是你的桌面虚拟机或者数据中心规模非常小，才可以使用这种相对简单的方式。



#### 总结：

虚拟机的网络类型:
**1 host-only网络**，其实就是两个虚拟机连到一个br0虚拟网桥上，而且不考虑访问外部的场景，只要虚拟机之间能够相互访问就可以了。
**2 桥接网络**
就是每个虚拟机的网卡都连接到网桥上，物理网卡也连接到网桥上，形成一个网络(所以桥接网络中虚拟机与物理机有相同的网段)，通过网桥连接到物理交换机上的一边，物理交换机的另一边连接着其他相同的网络。

在桥接模式下，每个虚拟机都会有虚拟网卡，在你的笔记本电脑上，会发现多了几个网卡，其实是虚拟交换机。

虚拟网卡、物理网卡都接到虚拟交换机上。

你的虚拟机的地址和你的笔记本电脑的，以及你旁边的同事的电脑的网段是一个网段。

在Linux中，桥接网络在每台机器上都创建网桥br0，虚拟机的网卡都连到br0上，物理网卡也连到br0上，所有的br0都通过物理网卡出来连接到物理交换机上。

问题:
在这种方式下，不但解决了同一台机器的互通问题，也解决了跨物理机的互通问题，因为都在一个二层网络里面，彼此用相同的网段访问就可以了。但是当规模很大的时候，会存在问题。

在一个二层网络里面，最大的问题是广播。一个数据中心的物理机已经很多了，广播已经非常严重，需要通过VLAN进行划分。如果使用了虚拟机，假设一台物理机里面创建10台虚拟机，全部在一个二层网络里面，那广播就会很严重，所以除非是你的桌面虚拟机或者数据中心规模非常小，才可以使用这种相对简单的方式。

**3 NAT网络**:
就是 虚拟机、虚拟DHCP服务器、虚拟路由器连接在一个网桥上，虚拟DHCP服务器为虚拟机动态的分配IP地址(使用的不是物理机物理DHCP服务器，所以虚拟机与物理机的网段并不相同)，虚拟机通过虚拟路由器把IP地址NAT为物理机的IP地址，通过物理网卡连接到外部网络。

在桌面虚拟化软件中使用NAT模式:
在这种方式下，你登录到虚拟机里面查看IP地址，会发现虚拟机的网络是虚拟机的，物理机的网络是物理机的，两个的网段并不相同。虚拟机要想访问物理机的时候，需要将地址NAT成为物理机的地址。

除此之外，它还会在你的笔记本电脑里内置一个DHCP服务器，为笔记本电脑上的虚拟机动态分配IP地址。因为虚拟机的网络自成体系，需要进行IP管理。为什么桥接方式不需要呢？因为桥接将网络打平了，虚拟机的IP地址应该由物理网络的DHCP服务器分配。

在Linux中，所有虚拟机、路由器、DHCP服务器都通过内网网口连接到一个网桥br0上，虚拟机要想访问互联网，需要通过br0连到路由器上，然后通过路由器将请求NAT成为物理网络的地址，转发到物理网络。

**进阶:**
还可以使用Linux命令，将虚拟机所在网络的网关的地址直接配置到br0上，不用DHCP Server，手动配置每台虚拟机的IP地址。
使用Linux命令开启物理机的转发功能，直接做路由器，而不用单独的路由器，直接在物理网卡上进行NAT，所有从这个网卡出去的包都NAT成这个网卡的地址。这样虚拟机就能直接上网了。

**小结:**
云计算的关键技术是虚拟化，这里我们重点关注的是，虚拟网卡通过打开TUN/TAP字符设备的方式，将虚拟机内外连接起来(虚拟机通过打开TUN/TAP字符设备的方式虚拟化出虚拟网卡，让虚拟机里面的应用觉得它们真有一张网卡。于是，所有的网络包都往这里发。网络包几经转手，最终从虚拟TAP网卡发出来，成为标准的网络包。数据终于从虚拟机里面，发到了虚拟机外面。)；

云中的网络重点关注四个方面，共享、隔离、互通、灵活。其中共享和互通有两种常用的方式，分别是桥接和NAT，隔离可以通过VLAN的方式。

### 容器网络：

详情可见：Docker.md

容器网络连接到物理网络的方式和虚拟机很像，通过桥接的方式实现一台物理机上的容器进行相互访问，如果要访问外网，最简单的方式还是通过NAT。

37 讲知识串讲：用双十一的故事串起碎片的网络协议（上）
